[{"content":"Function Storeとは Function Storeは、\nなんらかの単一の処理やAPIエンドポイントを「Function」として提供し、\nユーザーが目的を定義すると、\nエージェントが必要な「Function」を組み合わせることで、\nその目的を達成することができるプラットフォームです。\n主な特徴：\nプロンプトやコードで作成されたEndpointを持つ単一の処理をFunctionとして提供 プロンプトが書ければ誰でも開発者になれる低い参入障壁 ユーザーにはFunctionの利用量に応じた従量課金システムを採用 開発者には開発されたFunctionの利用料に応じた報酬システムを採用 なぜ必要か 開発者エコシステムの拡大 プロンプトという誰でも作れるアプリを流通させるマーケットを作る イノベーションの加速 課題定義 → 開発 → 実現のプロセスを誰でも高速に実現できるようにすることで、イノベーションのジレンマを潰す コスト効率の向上 LLMに対する多様な処理を集約することで、個々の利用に比べてハードウェア、ソフトウェアの両面からコスト効率化を目指す ビジネスモデル graph LR A[開発者] --\u003e|Function開発・提供| B[Function Store] B --\u003e|Combined Function（Agent）の提供| C[ユーザー] C --\u003e|利用料支払い| B B --\u003e|報酬支払い| A C --\u003e|目的定義・利用| B 類似サービスの問題点 AppStoreの課題 高い参入障壁 アプリ開発には専門知識と多大な時間投資が必要 審査プロセスが厳格で時間がかかる 固定的な価格設定 柔軟な料金体系の設定が困難 小規模な機能に対する適切な価格設定が難しい 大規模アプリ偏重 小規模な機能や特定のニーズに特化したソリューションが埋もれやすい 検索の困難性 多様性が上がりすぎて、マーケットからアプリを見つけることはできない ランキングも流動性が悪く、参考にならない Zapierの課題 複雑な自動化設定 非技術者にとって高度な自動化の設定が困難 限定的な統合オプション 特定のサービスやアプリケーションに依存 スケーラビリティの制限 大量の処理や複雑なワークフローへの対応に制限がある 利用者側にメリットがない 基本サブスクでコストを払うのみで、リターンはない GPTs（OpneAI）の課題 利用者がテック寄りの人間に偏ってる ニッチなニーズが生まれない GPTs開発者への報酬がない 競合はあるか まだわからない。\nAppleは頑張ってくれたらいいなって思ってる。Siri + ショートカット機能がユーザーのニーズには近いと思っている。\nFunction Storeの具体的な使用例 1. 不動産業者向け物件写真最適化システム ユーザー：中小規模の不動産会社 目的：「物件の写真をアップロードし、自動で色調整、不要物の削除、ウォーターマーク追加を行う」 使用するFunction： 画像アップロード Function 自動色調整 Function 不要物検出・削除 Function（AI画像生成技術を使用） ウォーターマーク追加 Function 結果：プロ級の物件写真を簡単かつ迅速に作成でき、物件の魅力を高められる 2. 飲食店向け口コミ分析ダッシュボード ユーザー：個人経営の飲食店オーナー 目的：「Google Maps、食べログ、インスタグラムの口コミを収集し、感情分析を行い、トレンドをグラフ化する」 使用するFunction： Google Maps口コミ取得 Function 食べログ口コミ取得 Function インスタグラム投稿取得 Function テキスト感情分析 Function トレンド分析 Function グラフ生成 Function 結果：複数プラットフォームの口コミを一元管理し、客観的な店舗評価とトレンドを把握できる 3. 多言語カスタマーサポートチャットボット ユーザー：グローバル展開を目指すEコマース企業 目的：「顧客からの問い合わせを自動で言語検出し、適切な言語で回答を生成。必要に応じて人間のオペレーターに引き継ぐ」 使用するFunction： 言語検出 Function 機械翻訳 Function（入力を英語に統一） 意図分類 Function（問い合わせ内容を分類） FAQ検索 Function 回答生成 Function 人間オペレーター引継ぎ判定 Function 翻訳 Function（回答を元の言語に翻訳） 結果：24時間体制の多言語サポートを低コストで実現し、顧客満足度を向上 4. 個人投資家向けAI投資アシスタント ユーザー：副業で株式投資を始めた会社員 目的：「指定した銘柄の財務データと市場動向を分析し、投資判断をサポートする」 使用するFunction： 株価データ取得 Function 財務データ取得 Function ニュース記事収集 Function センチメント分析 Function（ニュース記事の感情分析） テクニカル分析 Function ファンダメンタル分析 Function 投資判断生成 Function 結果：プロ並みの分析と判断材料を得られ、個人投資家の意思決定をサポート ","permalink":"https://konumaru.org/202505/functionstore%E6%A7%8B%E6%83%B3/","summary":"\u003ch2 id=\"function-storeとは\"\u003eFunction Storeとは\u003c/h2\u003e\n\u003cp\u003eFunction Storeは、\u003c/p\u003e\n\u003cp\u003eなんらかの単一の処理やAPIエンドポイントを「Function」として提供し、\u003c/p\u003e\n\u003cp\u003eユーザーが目的を定義すると、\u003c/p\u003e\n\u003cp\u003eエージェントが必要な「Function」を組み合わせることで、\u003c/p\u003e","title":"FunctionStore構想"},{"content":"成約までの全体像：5つのステップ アプローチ・初回商談 顧客との最初の接触。紹介やWeb問い合わせ、展示会など、さまざまなチャネルがある 相手企業の概要や事業分野、課題感を大まかに把握し、関係を構築し始める ニーズ確認・課題の明確化 顧客が抱える課題をヒアリングし、解決すべき優先度や要件を整理 顧客の想定予算や導入決定権者の有無なども同時に確認する ソリューション提案・デモ 明確化した課題に対して、具体的な解決策・メリットを示す デモやプロトタイプなども活用して導入後のイメージを高める 見積提示・交渉 予算とのすり合わせ・価格交渉・契約条件の調整を行う 不安や疑問点を解消し、最終合意に近づける クロージング（契約締結） 契約書取り交わし、顧客企業内の稟議などをサポートし、最終決定を得る ステップごとの規模別攻略ポイント ステップ1. アプローチ・初回商談 規模 主要な特徴 具体的なアプローチ スタートアップ 意思決定者に直接リーチしやすい\n新規技術やスピード感重視 トップアプローチ（代表直）\n小規模PoC提案\n伴走姿勢を伝える 中小企業 ITに不慣れな経営者が多い\n比較的スピード決済可能 紹介の活用\nわかりやすい表現を意識\n丁寧なヒアリング 大企業 窓口と決裁者が異なる\n実績・信頼重視 紹介や既存ネットワークを活用\n導入実績や成功事例を提示\n比較検討時の優位性を強調 信頼獲得のポイント：初回接触時 スタートアップ\n柔軟さとスピードをアピール CTOや技術責任者との早期接点づくり（技術的理解を深めるため） アイデアベースの提案よりも「実現可能な範囲」の現実解を提示 「他社はこうしている」という業界情報の提供で価値を示す リソース不足を前提とした支援姿勢を提案（例: 開発リソース、人脈紹介など） 中小企業\n難しい言葉を避け、信頼できる相談相手として振る舞う 経営者の関心事（コスト削減・売上向上・業務効率化など）に焦点を当てる 成功事例を「Before/After」で具体的に示す（理想は同業他社の事例） 初回から提案ありきではなく「理解する姿勢」を徹底する 業界特有の課題への理解をアピール（事前リサーチが重要） 大企業\n担当者が社内で話しやすいような資料・実績を準備 自社サービスの市場での位置づけを明確に（競合比較表など） 初回面談での深掘りよりも「2回目面談の約束」を優先する戦略 キーパーソンマップを早期に作成（意思決定者と影響者の特定） 部署間の利害関係や組織構造への理解を示す 業界展示会やセミナーなどでの接点づくりも効果的 ステップ2. ニーズ確認・課題の明確化 規模 特徴 アプローチ スタートアップ 変動性が高い\n課題が未整理 短期・中長期の開発意図を明確化\n将来の拡張性を提案に盛り込む 中小企業 経営と現場のズレ\n要件が曖昧になりやすい 現場ヒアリングを重視\n数値・図で課題を可視化 大企業 複数部署にまたがる\nRFP形式も多い 各部門の利害を把握し統合\nRFPの背景や目的を確認 信頼獲得のポイント：ヒアリング時 スタートアップ\n経営視点で共に課題を整理 「MVP」の概念を用いて現実的な範囲設定を支援 優先度マトリクス（重要性×緊急性）を一緒に作成 短期的な課題と長期ビジョンの両方を引き出す質問設計 資金調達状況や事業フェーズに合わせた提案前提を構築 技術負債を生まない設計思想を示す（将来コストの削減） 中小企業\n現場と経営の橋渡し役として信頼を得る 業務フローの可視化ワークショップを実施 定量的な問題規模の特定（例: 月◯時間のロス、年間◯円のコスト） 経営者と現場担当者の双方を含めた合同ヒアリングの設定 競合他社や業界標準との比較データの提供 困りごとから始め、徐々に解決策イメージへと誘導する質問設計 大企業\n横串を通す形でヒアリング、社内調整を支援 部門間の優先度の違いを可視化して調整（合意形成ツールとして） RFPの「行間を読む」スキル（明文化されていない真の課題を特定） 既存システム構成の詳細把握と連携ポイントの特定 ステークホルダー分析と根回し戦略の立案支援 政治的な力学を考慮した提案準備（反対派への対応戦略含む） 外部環境要因（規制変更・業界動向）の分析と提供 ステップ3. ソリューション提案・デモ 規模 特徴 アプローチ スタートアップ シンプルな提案を好む\n試せるものに価値を感じる\nリソース制約（時間・資金・人材）あり MVP提案\nデモ環境で導入後を想像させる\n「共創」の姿勢を示す 中小企業 ROIを重視\n合理的な説明に納得すれば決定は早い\nIT導入への不安感が強い 数字を用いた説得\nスケジュール・体制も説明\n効果の「見える化」徹底 大企業 システム連携・リスク重視\n複数部門の利害調整が必要\nセキュリティ・コンプライアンス要件厳格 大規模開発実績を提示\nリスク低減策を明示\n社内説明支援資料の充実 信頼獲得のポイント：提案・デモ時 スタートアップ\nスモールスタートと将来拡張性の両方を提示 「一緒に作り上げる」共創姿勢を強調 最初の2週間で形になるデリバラブルを明確化 同フェーズ企業での成功体験（失敗から学んだ知見も）を共有 中小企業\n「毎月◯時間の削減」など具体的数値で効果提示 「最初の1ヶ月」「3ヶ月後」など段階的な変化イメージを視覚化 同業種・同規模企業の導入事例を詳細に共有 経営者が現場に説明しやすい資料を提供 大企業\nセキュリティ認証・監査体制の詳細提示 提案先担当者が社内説明で使える資料の提供 想定されるリスクとその対応策一覧を準備 プロジェクト体制図と役割分担の明確化 ステップ4. 見積提示・交渉 規模 特徴 アプローチ スタートアップ 資金調達状況に依存\n価格より効果重視の傾向も 小さく始める提案と拡張可能性の提示\n段階導入 中小企業 明確な上限予算あり\n値下げ要望あり ROIシミュレーション\nライトプラン・段階導入 大企業 契約内容・項目精査が厳格 コスト内訳の提示\n契約条件の準備と法務対応を意識 信頼獲得のポイント：交渉時 スタートアップ\n資金調達状況やバーンレートを考慮した段階的な投資プラン提案 「最低限必要な部分」と「あったら良い機能」の明確な切り分け 最初の3ヶ月でのROI可視化を重視（投資回収の早期化） コアとオプション機能の分割提案（拡張可能性を担保） 低コストで始め、成果に応じて段階的に投資増やす「成功報酬型」提案 共同プロジェクトとしての位置づけ（リスク・リワード共有モデル） 契約内容より「成果物」「プロセス」に重点を置いた説明 中小企業\n初期投資と月額運用コストの明確な切り分け 数値で示すROI試算（「年間◯百万円のコスト削減」など） 競合見積もりとの比較ポイントを先回りして説明 「予算内で最大の効果」を出すための機能調整案の提示 同業他社での導入事例とコスト感の共有（参考指標） 値引きよりも「サービス追加」で価値向上を図る交渉術 経営者の関心事（売上増・コスト削減・リスク低減）に合わせた説明 大企業\n予算策定のタイミングを把握し、年度計画に組み込める提案 コスト構造の透明化（人件費・ライセンス費・保守費など） 見積内訳の詳細化と根拠説明（担当者の社内説明用） 法務・調達部門が指摘しそうな点を先回りして補足説明 複数年契約のメリット提示（年間コスト削減など） SLAなど契約条件の明確化と対応可能範囲の提示 競合製品との詳細比較表の提供（選定根拠の強化） 将来的な拡張性・スケーラビリティの説明 ステップ5. クロージング（契約締結） 規模 特徴 アプローチ スタートアップ 意思決定は早いが方針転換もある 最終確認を頻繁に\n導入後の効果を再共有 中小企業 経営者が納得すればスムーズ 経営層の不安解消に集中\nサポート体制も示す 大企業 稟議・法務プロセスが複雑 稟議資料の支援\nセキュリティやコンプラ対応も抜かりなく 信頼獲得のポイント：契約締結時 スタートアップ: こまめな進捗共有で安心感 中小企業: サポート含めた「頼れる存在」になる 大企業: 稟議通過を支援する「社内代理人」的な動き 大企業・外資系の意思決定プロセス可視化 大企業や外資系企業では、意思決定プロセスが複雑で多段階になることが多いです。キーパーソンや承認フローを可視化することで、営業戦略の立案や根回しがしやすくなります。\n典型的な意思決定フロー（例：flowchart） flowchart LR A[現場担当] --\u003e B[部門長] B --\u003e C[情報システム部] C --\u003e D[法務・コンプラ] D --\u003e E[役員会・経営層] 現場担当: 実務上の課題や要件を整理 部門長: 部門予算やリソース配分を決定 情報システム部: 技術要件・システム連携・セキュリティ審査 法務・コンプラ: 契約・規約・リスクチェック 役員会・経営層: 最終承認 キーパーソンマップの例 flowchart TD %% クライアント側組織階層 subgraph Client A1[現場担当] A2[部門長] A3[情報システム部] A4[法務] A5[経営層] A1 --\u003e A2 A2 --\u003e A5 A2 -- 調整 --\u003e A3 A2 -- 調整 --\u003e A4 end %% 営業側 subgraph Vendor B1[営業担当] B2[技術担当] end %% アプローチ・調整の流れ B1 -- ヒアリング・提案 --\u003e A1 B1 -- 根回し・調整 --\u003e A2 B2 -- 技術説明 --\u003e A3 ROI・ビジネスケースの定量例 ROI（投資対効果）やビジネスケースを定量的に示すことで、顧客の納得感や説得力が高まります。\nROI計算のサンプル ROI（%） = （年間コスト削減額 − 年間投資額） ÷ 年間投資額 × 100 例 項目 金額（円） 年間コスト削減額 3,600,000 年間投資額 1,200,000 ROI (3,600,000-1,200,000)/1,200,000×100=200% 投資回収期間（Payback Period） 投資回収期間 = 初期投資額 ÷ 年間コスト削減額 例 項目 金額（円） 初期投資額 2,000,000 年間削減額 1,000,000 回収期間 2,000,000 ÷ 1,000,000 = 2年 クロージング後のフォローアップ 契約締結後のフォローアップは、顧客満足度の向上やリファレンス獲得、追加受注につながる重要な活動です。\nフォローアップのポイント カスタマーサクセスの徹底 導入後の定期的な進捗確認・課題ヒアリング 利用状況の可視化・活用促進サポート トラブル時の迅速な対応 リファレンス獲得 成功事例インタビューや導入事例の公開依頼 顧客の声を新規営業やプロダクト改善に活用 追加提案・アップセル 利用状況に応じた新機能・追加サービスの提案 顧客の成長や変化に合わせた継続的な提案 まとめ 成約プロセスは共通だが、各ステップの対応は企業規模で調整すべき スタートアップ: スピードと柔軟性、技術伴走が鍵 中小企業: 分かりやすさと費用対効果で納得感を得る 大企業: 実績と体制、社内調整支援で信頼を獲得 → 購買プロセスに寄り添い、各規模に最適な手を打つことで、成約率は確実に上がる。\nまとめの補足\n大企業・外資系では「意思決定フローの可視化」と「根回し」が成約率向上の鍵 ROIやビジネスケースは定量的に示すことで説得力が増す クロージング後のフォローアップがリファレンス獲得や追加受注につながる ","permalink":"https://konumaru.org/202504/it%E5%8F%97%E8%A8%97%E5%96%B6%E6%A5%AD%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E6%88%90%E7%B4%84%E3%81%BE%E3%81%A7%E3%81%AE%E3%83%97%E3%83%AD%E3%82%BB%E3%82%B9%E3%81%A8%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88/","summary":"\u003ch2 id=\"成約までの全体像5つのステップ\"\u003e成約までの全体像：5つのステップ\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eアプローチ・初回商談\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e顧客との最初の接触。紹介やWeb問い合わせ、展示会など、さまざまなチャネルがある\u003c/li\u003e\n\u003cli\u003e相手企業の概要や事業分野、課題感を大まかに把握し、関係を構築し始める\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eニーズ確認・課題の明確化\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e顧客が抱える課題をヒアリングし、解決すべき優先度や要件を整理\u003c/li\u003e\n\u003cli\u003e顧客の想定予算や導入決定権者の有無なども同時に確認する\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eソリューション提案・デモ\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e明確化した課題に対して、具体的な解決策・メリットを示す\u003c/li\u003e\n\u003cli\u003eデモやプロトタイプなども活用して導入後のイメージを高める\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e見積提示・交渉\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e予算とのすり合わせ・価格交渉・契約条件の調整を行う\u003c/li\u003e\n\u003cli\u003e不安や疑問点を解消し、最終合意に近づける\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eクロージング（契約締結）\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e契約書取り交わし、顧客企業内の稟議などをサポートし、最終決定を得る\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"ステップごとの規模別攻略ポイント\"\u003eステップごとの規模別攻略ポイント\u003c/h2\u003e\n\u003ch3 id=\"ステップ1-アプローチ初回商談\"\u003eステップ1. アプローチ・初回商談\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003e規模\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e主要な特徴\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e具体的なアプローチ\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003eスタートアップ\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e意思決定者に直接リーチしやすい\u003cbr\u003e 新規技術やスピード感重視\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eトップアプローチ（代表直）\u003cbr\u003e 小規模PoC提案\u003cbr\u003e伴走姿勢を伝える\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e中小企業\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003eITに不慣れな経営者が多い\u003cbr\u003e 比較的スピード決済可能\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e紹介の活用\u003cbr\u003e わかりやすい表現を意識\u003cbr\u003e 丁寧なヒアリング\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e大企業\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e窓口と決裁者が異なる\u003cbr\u003e 実績・信頼重視\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e紹介や既存ネットワークを活用\u003cbr\u003e 導入実績や成功事例を提示\u003cbr\u003e 比較検討時の優位性を強調\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch4 id=\"信頼獲得のポイント初回接触時\"\u003e信頼獲得のポイント：初回接触時\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eスタートアップ\u003c/strong\u003e\u003c/p\u003e","title":"IT受託営業における成約までのプロセスとポイント"},{"content":"概要 SpreadsheetでLLMを使えるようにした Crawlerと組み合わせることでwebページの要約、情報抽出ができる Prompt Engineering頑張るとかなり使えた なぜ作ろうと思ったのか 元々はChatGPT in Google Sheets™ and DocsというChrome拡張を使っていて、Open AIのAPI Keyさえあれば便利に使えた。\nのだが、最近独自の課金体系を設けるようになってしまったので、それはちょっと、、と思って自作することにした。\nただし、独自の課金体系があるくらいには機能が充実しているっぽく、いろいろなユースケース向けのプリセットやGoogle Docs, Google Slidesにも対応している。 あとはユーザーがAPI Keyを不要にすることで、利用する敷居を下げている。\n自作GPT関数の作り方 作り方といってもSpreadsheetのスクリプトエディタにコードを書くだけである。\nAPI KeyはOpenAIのサイトで取得し、GASのスクリプトプロパティに設定する。\nfunction GPT(prompt, temperature=1.0, maxToken=1024) { //スクリプトプロパティに設定したOpenAIのAPIキーを取得 const apiKey = PropertiesService.getScriptProperties().getProperty(\u0026#39;API_KEY\u0026#39;); //OpenAIのAPIで利用するモデルとしてgpt-4oを設定 const model = \u0026#39;gpt-4o\u0026#39;; //GPTのAPIのエンドポイントを設定 const apiUrl = \u0026#39;https://api.openai.com/v1/chat/completions\u0026#39;; //GPTに投げるメッセージを定義(ユーザーロールの投稿文のみ) const messages = [ {\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: prompt} ]; //OpenAIのAPIリクエストに必要なヘッダー情報を設定 const headers = { \u0026#39;Authorization\u0026#39;:\u0026#39;Bearer \u0026#39;+ apiKey, \u0026#39;Content-type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;X-Slack-No-Retry\u0026#39;: 1 }; //GPTのモデルやトークン上限、プロンプトをオプションに設定 const options = { \u0026#39;muteHttpExceptions\u0026#39; : true, \u0026#39;headers\u0026#39;: headers, \u0026#39;method\u0026#39;: \u0026#39;POST\u0026#39;, \u0026#39;payload\u0026#39;: JSON.stringify({ \u0026#39;model\u0026#39;: model, \u0026#39;max_tokens\u0026#39; : maxToken, \u0026#39;temperature\u0026#39; : temperature, \u0026#39;messages\u0026#39;: messages}) }; //OpenAIのGPTにAPIリクエストを送り、結果を変数に格納 const response = JSON.parse(UrlFetchApp.fetch(apiUrl, options).getContentText()); return response.choices[0].message.content; } function test() { console.log(GPT(\u0026#34;test\u0026#34;)); } 以下の部分で様々なPrompt Engineeringを行うことができる。\n例えば、テーブル分析に向いてる関数、要約に向いてる関数、質問応答に向いてる関数など作ることができると思う。\nconst messages = [ {\u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: prompt} ]; Spreadsheetでの使い方 使い方は簡単で、セルに=GPT(\u0026quot;hogehoge\u0026quot;)と入力するだけである。\nその他のセル情報を活用したい場合は、\n=GPT($B2\u0026amp;\u0026#34;から\u0026#34;\u0026amp;C$1\u0026amp;\u0026#34;を簡潔に取得してください\u0026#34;) のようにすることで、セルの情報を活用することができる。\nまた、以下のコードと組み合わせることで、webページのテキスト情報を抽出し、要約や情報抽出ができる。\n=ARRAYFORMULA(TRIM(REGEXREPLACE(TEXTJOIN(\u0026#34; \u0026#34;, TRUE, IMPORTXML(A2, \u0026#34;//body//text()[not(ancestor::script)][not(ancestor::style)][normalize-space()]\u0026#34;)), \u0026#34;\\s+\u0026#34;, \u0026#34; \u0026#34;))) 使い方のイメージは以下の通り。\n使い方 Tips Webページごとに情報構造が異なるので、Crawlerの設定を変えることで、情報抽出の精度を上げることができる。 抽出したい情報に併せてGPT関数内のプロンプトをカスタマイズすることで、より適切な情報抽出ができる。 e.g. =GPT($B2\u0026amp;\u0026quot;から\u0026quot;\u0026amp;D$1\u0026amp;\u0026quot;をYYYY年mm月dd日（月）形式で該当部分の年月日、曜日のみを出力してください\u0026quot;) おまけ Perplexity version function Perplexity(prompt, temperature = 0.2, maxTokens = 2048) { // スクリプトプロパティに設定した Perplexity AI の API キーを取得 const apiKey = PropertiesService.getScriptProperties().getProperty(\u0026#39;PERPLEXITY_API_KEY\u0026#39;); // Perplexity AI の API で利用するモデルを設定 const model = \u0026#39;llama-3.1-sonar-small-128k-online\u0026#39;; // Perplexity AI の API のエンドポイントを設定 const apiUrl = \u0026#39;https://api.perplexity.ai/chat/completions\u0026#39;; // API に送信するメッセージを定義 const messages = [ { \u0026#39;role\u0026#39;: \u0026#34;system\u0026#34;, \u0026#39;content\u0026#39;: \u0026#34;You are a helpful assistant.\u0026#34;}, { \u0026#39;role\u0026#39;: \u0026#39;user\u0026#39;, \u0026#39;content\u0026#39;: prompt } ]; // API リクエストに必要なヘッダー情報を設定 const headers = { \u0026#39;Accept\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Authorization\u0026#39;: \u0026#39;Bearer \u0026#39; + apiKey }; // API リクエストのオプションを設定 const options = { \u0026#39;muteHttpExceptions\u0026#39;: true, \u0026#39;headers\u0026#39;: headers, \u0026#39;method\u0026#39;: \u0026#39;POST\u0026#39;, \u0026#39;payload\u0026#39;: JSON.stringify({ \u0026#39;model\u0026#39;: model, \u0026#39;messages\u0026#39;: messages, \u0026#39;max_tokens\u0026#39;: maxTokens, \u0026#39;temperature\u0026#39;: temperature }) }; // API リクエストを送信し、結果を変数に格納 const response = JSON.parse(UrlFetchApp.fetch(apiUrl, options).getContentText()); // レスポンスから生成されたテキストを返す return response.choices[0].message.content; } ","permalink":"https://konumaru.org/202411/spreadsheet%E3%81%A7%E8%87%AA%E4%BD%9Cgpt%E9%96%A2%E6%95%B0%E3%82%92%E4%BD%BF%E3%81%86/","summary":"\u003ch2 id=\"概要\"\u003e概要\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eSpreadsheetでLLMを使えるようにした\u003c/li\u003e\n\u003cli\u003eCrawlerと組み合わせることでwebページの要約、情報抽出ができる\u003c/li\u003e\n\u003cli\u003ePrompt Engineering頑張るとかなり使えた\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"なぜ作ろうと思ったのか\"\u003eなぜ作ろうと思ったのか\u003c/h2\u003e\n\u003cp\u003e元々は\u003ca href=\"https://workspace.google.com/marketplace/app/chatgpt_for_google_slides_docs_sheets/451400884190\"\u003eChatGPT in Google Sheets™ and Docs\u003c/a\u003eというChrome拡張を使っていて、Open AIのAPI Keyさえあれば便利に使えた。\u003c/p\u003e","title":"Spreadsheetで自作GPT関数を使う"},{"content":"はじめに ダッシュボードを作って、 定量的な意思決定をして、 データドリブンに業務を進めるたい！と言ったら誰もが素晴らしい取り組みだと言ってくれると思う。\nでも実際にはデータがない、ダッシュボードがを作れる人がいない、なんとかダッシュボードを作ったがでーたが更新されない、ついにはダッシュボードを見なくなった。ということがよくある。\n目を通したい記事・資料 デジタル庁のダッシュボードデザインガイド デジタル庁 政策ダッシュボード一覧 正直デジタル庁の資料を読んで、その通りに実施すれば間違いないと思う。\nダッシュボードつくるときの目的 組織で現状、目標を共有する 目標達成のための改善点を見つける 利用者と要件定義するときの心構え どんなデータがみたいか どんなグラフにしたいか からコミュニケーションをしない。\n目標はなにか ダッシュボードのトップの左上に設置する 誰が、どんな意思決定をしたいか ひとごとにダッシュボードページを分けて、 意思決定から逆算した必要なデータ、グラフを選定する 誰と共有したいか 見れない人がいるツール、設定だと困るので最初に確認する ","permalink":"https://konumaru.org/202410/%E3%83%80%E3%83%83%E3%82%B7%E3%83%A5%E3%83%9C%E3%83%BC%E3%83%89%E3%81%A4%E3%81%8F%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%AB%E3%81%BF%E3%82%8B%E8%A8%98%E4%BA%8B/","summary":"\u003ch2 id=\"はじめに\"\u003eはじめに\u003c/h2\u003e\n\u003cp\u003eダッシュボードを作って、\n定量的な意思決定をして、\nデータドリブンに業務を進めるたい！と言ったら誰もが素晴らしい取り組みだと言ってくれると思う。\u003c/p\u003e","title":"ダッシュボードつくるときにみる記事"},{"content":"GASを使ってスプレットシートのデータをテーブル風に操作したら便利だった。 そのときのコードのメモ。\npandasのような集計、集約などはGASでやるのはしんどそうなので、そこはスプレットシート側の機能を使うのがよさそうだった。 GASはあくまでCRUDに使うのがよさそう。\nGAS Insert function insert(sheet, id, record) { sheet.appendRow(record); return id; } Update function update(sheet, id, record) { const data = sheet.getDataRange().getValues(); for (let i = 1; i \u0026lt; data.length; i++) { if (data[i][0] == id) { console.log(record.length); sheet.getRange(i+1, 1, 1, record.length).setValues([record]); return true; } } return false; } Upsert function upsert(sheet, id, record) { if (update(sheet, id, record)) { return id; } else { return insert(sheet, id, record); } } ","permalink":"https://konumaru.org/202410/gas%E3%81%A7%E3%82%B9%E3%83%97%E3%82%B7%E3%82%92%E3%83%86%E3%83%BC%E3%83%96%E3%83%AB%E6%93%8D%E4%BD%9C%E3%81%97%E3%81%9F%E3%81%84/","summary":"\u003cp\u003eGASを使ってスプレットシートのデータをテーブル風に操作したら便利だった。\nそのときのコードのメモ。\u003c/p\u003e\n\u003cp\u003epandasのような集計、集約などはGASでやるのはしんどそうなので、そこはスプレットシート側の機能を使うのがよさそうだった。\nGASはあくまでCRUDに使うのがよさそう。\u003c/p\u003e","title":"GASでスプシをテーブル操作したい"},{"content":"転職をきっかけに新しいパソコンを買う機会がやってきた。\nずっと自分のLaptopが欲しかったの買うことにした。\n買ったのは、ThinkPad X1 Carbon Gen 12 だ。\nスペックは以下の通り。\nプロセッサー: インテル® Core™ Ultra 7 プロセッサー 155U OS: Windows 11 Pro 64bit (日本語版) メモリ: 32 GB LPDDR5X-7500MHz (オンボード) ストレージ: 1 TB SSD M.2 2280 PCIe-NVMe Gen4 ディスプレイ: 14\u0026quot; 2.8K OLED (2880 x 1800), 400 nit, 120Hz グラフィックス: 内蔵グラフィックス カメラ: IRカメラ、1080p FHDカメラ 本体カラー: ブラック キーボード: バックライト付、英語配列 指紋センサー: あり グラボが乗っているものを買おうか迷ったが、自宅にデスクトップがあるし、eGPUも気になっているし、今回は内蔵グラフィックスで我慢することにした。それに持ち歩くことを考えると消費電力なども気になった。\nお値段は33万円とお高かったが、まあ仕方ない。妥協するとまたいいものが欲しくなる。\n","permalink":"https://konumaru.org/202407/%E4%BA%BA%E7%94%9F%E5%88%9D-windows-laptop-%E8%B3%BC%E5%85%A5/","summary":"\u003cp\u003e転職をきっかけに新しいパソコンを買う機会がやってきた。\u003c/p\u003e\n\u003cp\u003eずっと自分のLaptopが欲しかったの買うことにした。\u003c/p\u003e\n\u003cp\u003e買ったのは、ThinkPad X1 Carbon Gen 12 だ。\u003c/p\u003e","title":"人生初 Windows Laptop 購入"},{"content":"はじめに この記事ではクーポン配布施策について書いていく。\nこういった施策をやるよ、となったときに自分なりのテンプレートがあるのであとで思い出せるように残しておこうと思った。\nクーポン配布の背景と目的 クーポン配布の目的はさまざま考えられるが、この記事内では以下のような目的とする。\n売り上げを伸ばしたい 予算を使い切りたい １は、主に新規ユーザーの獲得や１人あたりの購買単価を上げることが考えられる。\n２は、配布したクーポンをユーザーが利用することで予算が消費される。\n過去データから考える 最終的に決定するディスカウント条件については、話をシンプルにするために今回は「X円以上の購入でY円割引」という形で考える。ここから先ではこのX, Yを決定する。\n過去の適当な期間を対象に、ユーザー１人あたりの購買単価をヒストグラムを見ることから始める。 適当な期間とは、直近1ヶ月や3ヶ月など適当な期間で良い。さらにサービスのドメイン知識があるならユーザーが離反する期間を考慮するといい。\n大体こういうのは下図のようなロングテールのグラフになるだろ、という仮定でデモデータを生成した。 X軸は１人あたりの購買金額、Y軸はその金額を購入したユーザー数を表している。\nこのグラフは左側であるほど無課金・低課金ユーザー、右側であるほどが重課金ユーザーとなる。\n結論から言うと売り上げを上げるポテンシャルがあるユーザーは左側のユーザーであり、クーポンの配布対象のユーザーとなる。\n仮に右側のユーザーにクーポンを配布したとすると、彼らはすでに買いたいものが明確であり、クーポンがなくても購買行動をする。そのため事業者側からするとただ値下げをしているだけであり、売上を伸ばすことは難しい。\n昔聞いた「行列ができるラーメン屋の行列にトッピング無料券を配布しても意味ないでしょ？」と言う例えがわかりやすかった。\nしかし無課金ユーザーのみだとそもそも欲しいものがなかったり、サービスから離反しきっている可能性がありディスカウント件を配布しても期待される効果が薄い。\nつまり、どこにディスカウント条件設けるといいかというと、程よく欲しいものがあり、サービスを離反していないユーザーがいそうなところに基準（＝X）を設けるとよい。\n最初は以下のように大体でいい。大体でいんです、最初は。\n生成されたサンプルデータから 今回はX=1,000円, Y=20%という条件でディスカウントを適用することにする。 わかりやすくいうと「1,000円以上の購入で200円割引」ということ。\nユーザーに価値が伝わるUXを考える せっかくお金を配って、ユーザーにとってメリットもあるはずなのに、それが伝わらないと意味がない。 またユーザーがそれを受け入れやすいような意味づけをすることも重要。\nとはいえ難しい話ではなくて、以下のようなことを指している。\n見せ方で言うと、1,000円以上の購入で200円割引、2 Buy 1 Get 1 Free、10,000円以上で送料無料、などがある。\n動機付けで言うと、誕生日、初回購入、時間制限付き\nとにかくユーザーがメリットを感じるかを確認することが重要。\nレポーティングの雛形 Outlineは、\nディスカウント条件の決定理由 ディスカウント条件の詳細 X円以上の購入でY円割引 有効期限 適用条件 配布実績 配布ユーザー数 クーポン利用率 平均購買単価の変化 購買UU数の変化 ディスカウント条件の変更案 大体こう言うことを書いておけばよくて、クーポン配布後の購買単価の分布は大体以下のようになる。\n「データ分析の力 因果関係に迫る思考法」では、集積分析という名前で紹介されている。\nちなみに、今回のサンプルデータでは以下のように変化した。\n通常時 平均購買単価: 916 円 累計購買金額: 91,618,703 円 クーポン適用後 平均購買単価: 963 円 累計購買金額: 96,305,593 円 平均購買単価が、約5%上昇したことになる。\nあとは先ほど決めた、X,Yやユーザーへの伝え方を変えるABテストを繰り返すことで、より効果的なディスカウント条件を見つけることができる。\nマニュアルが機能する前提条件 ここまでみてもらったことが再現するにはいくつか条件がある。\n購買単価の分布がロングテールになっていること ディスカウント条件がユーザーに伝わっていること ユーザーが自身の購買単価を操作可能であること ← これが一番重要 まとめ 平均購買単価のヒストグラムを見て、ディスカウント条件を決定するといいよ ディスカウント条件はユーザーに伝わるように工夫するといいよ レポートの雛形は作っておくといいよ X, Yを操作する、ユーザーへの伝え方を変えるABテストをするといいよ ABテストができない環境でもヒストグラムのBinごとの平均購買率の変化を見るといいよ ユーザーが自身の購買単価を操作可能であることが重要だよ 余談：時限式クーポンについて 「ユーザーへの伝え方」の文脈で、時限式クーポンについて触れておく。\nこの記事で最初においた目的として「売上を伸ばしたい」というのがあった。\n実は時限式クーポンは、ユーザーの意思決定を早める効果は期待されるのだがトータルの売上を伸ばす効果はあまり期待できない。なぜかというと明日買おうと思っていたものを今日買うようになったとしても、トータルの売上は変わらないからだ。\nただしクーポン使用率が高かったり、瞬間的な売上を伸ばす効果はあるためレポーティングではその実態を把握できることは少ない。わかりやすく今日の売り上げは伸びるから。\n長期的にみて意味のあることかも意識しないといけないよね、と思ってる。\nその他これについて個人的に思うことは以下の通り。\n時間制限は短ければ短いほど効果がある 効能としてはユーザーの意思決定を早める効果がある 予算消化したいとき、KPI達成したいとか便利 見せ方は派手などよい 1ヶ月とか1年とかの有効期限はなんなの？ 配る側は忘れることを期待してる 事業会社が合法的に発行できる通貨であり、失効条件も握っているためクーポン使用率を操作したいときに便利 そのため見せ方も目立たない方がいい Source Code User Class\nclass User: def __init__(self, user_id): self.user_id = user_id self.max_purchase_amount = 10000 def generate_purchase_amount(self): purchase_amount = np.random.pareto(a=2.0) * self.max_purchase_amount / 10 purchase_amount = min(max(purchase_amount, 0), self.max_purchase_amount) return purchase_amount def apply_coupon( self, purchase_amount, coupon_threshold: float = 1000.0, discount_rate=0.2, ): if purchase_amount \u0026lt; coupon_threshold: probability = 1 - (coupon_threshold - purchase_amount) / coupon_threshold if np.random.rand() \u0026lt; probability: purchase_amount += coupon_threshold * discount_rate return purchase_amount 通常時の購入金額の分布\nnum_users = 100000 users = [User(user_id=i) for i in range(num_users)] purchase_amounts = [user.generate_purchase_amount() for user in users] plt.hist(purchase_amounts, bins=100) plt.xlabel(\u0026#39;Purchase Amount (Yen)\u0026#39;) plt.ylabel(\u0026#39;Number of Users\u0026#39;) plt.title(\u0026#39;Distribution of Purchase Amounts\u0026#39;) plt.show() クーポン適用後の購入金額の分布\nusers = [User(user_id=i) for i in range(num_users)] coupon_threshold = 1000 purchase_amounts = [] for user in users: amount = user.generate_purchase_amount() amount = user.apply_coupon(amount, coupon_threshold, discount_rate=0.2) purchase_amounts.append(amount) plt.hist(purchase_amounts, bins=100) plt.vlines(coupon_threshold * 0.95, 0, len(users) * 0.15, colors=\u0026#39;r\u0026#39;, linestyles=\u0026#39;dashed\u0026#39;, label=\u0026#34;coupon threshold\u0026#34;) plt.xlabel(\u0026#39;Purchase Amount (Yen)\u0026#39;) plt.ylabel(\u0026#39;Number of Users\u0026#39;) plt.title(\u0026#39;Distribution of Purchase Amounts with Coupon Applied\u0026#39;) plt.legend() plt.show() 平均購買単価\nfrom typing import List import numpy as np def purchase_statistics(purchase_amounts: List[float]): average_amount = np.mean(purchase_amounts) total_amount = np.sum(purchase_amounts) users_between_1000_1500 = len([amount for amount in purchase_amounts if 1000 \u0026lt;= amount \u0026lt;= 1500]) print(f\u0026#34;平均購買単価: {average_amount:.2f}\u0026#34;) print(f\u0026#34;累計購買金額: {total_amount:.2f}\u0026#34;) ","permalink":"https://konumaru.org/202406/%E3%82%AF%E3%83%BC%E3%83%9D%E3%83%B3%E9%85%8D%E5%B8%83%E6%96%BD%E7%AD%96%E3%81%AE%E9%89%84%E6%9D%BF%E3%83%9E%E3%83%8B%E3%83%A5%E3%82%A2%E3%83%AB/","summary":"\u003ch2 id=\"はじめに\"\u003eはじめに\u003c/h2\u003e\n\u003cp\u003eこの記事ではクーポン配布施策について書いていく。\u003c/p\u003e\n\u003cp\u003eこういった施策をやるよ、となったときに自分なりのテンプレートがあるのであとで思い出せるように残しておこうと思った。\u003c/p\u003e","title":"クーポン配布施策の鉄板マニュアル"},{"content":"導入 ML Eng -\u0026gt; PdM というキャリアを進んでいる背景もあり、なんか機械学習を使ったいい感じの企画をしてくれよ、という話は多数耳にする。\nとあるスカウトサービス経由でカード発行もやっているクレジットカード事業でそのような需要があることを耳にした。スカウトが来ただけなので働いてはいない。\n率直に「何に機械学習を使えるのだ？」と思ったので少し考えてみたくなって記事を書くことにした。\n市場を眺める クレジットカードの発行も含んだ私が使ったことあるサービスは以下の通り。\nKyash, B4/3, Revolut, LINE Payカード\nどれも物理的なカードが発行でき、相互送金ができ、B4/3のみは複数ユーザーでの利用ができる。\n実際に使ってみた所感としては、クレジットカードのスケープゴートができたような感覚であり非常によかった。具体的には、\n紛失時にアプリから利用を停止できる クレジットカードからのチャージによるポイントの二重取得 送金機能 クレカ変更の影響の軽減(メインで使うカードは変わらないという意味) このように個人としての利用経験もよかった。\n昨今はカードレスクレジットカードやhogehoge Pay、QR決済なども増えているが、物理のクレジットカードの発行はまだまだ需要があると考えられる。 特に日本ではなぜかわからないが、クレカのタッチ決済が機能していない店舗が多数ある。\nまた昨今のこのような事業においては家計簿アプリとクレカが連携しているものも多い。 今回も上記にフォーカスして思考を巡らせてみる。\n事業への理解を深める ビジネスモデルとしてはシンプルだと思っていて大体以下の２点に落ち着くと思ってる。\n発行したクレカの利用料金から手数料を取る 有料プランがある場合はその料金を取る 要は、発行したクレカを使ってもらうことが事業の成長に繋がる。 また、付加価値としてついている家計簿機能も使ってもらうことが事業の成長に繋がる。 さらにいうと、付加価値があることでクレカの利用を促進することも事業の成長に繋がる。\n想定するサービスの前提 これはこの後機械学習の活用方法について検討するにあたる前提を揃える。\n想定されるサービスは、\nプリペイド式のクレジットカードを発行できる サービスが提供するカードを使うと家計簿が記録される オプション機能 送金機能 複数人での利用管理 ポイント付与 ユーザーが求める価値を言語化してみる（サービスが提供したい価値とも言える） 「機械学習が事業に貢献するなら」という話をするために、ユーザーが求める価値を言語化してみる。\n支出を管理できる 複数人で財布をシェアできる 安全性が高い（カードをアプリから即時に止められるなど） 「価値」の定義が正として、機械学習の活用方法を模索する 私は今回「支出を管理できる」という価値にフォローカスして機械学習の活用方法を模索することにした。 きっと手札をもっと多く持っていたり、他の方が考える価値を見つけることもできる人もいるだろうと思う。\n今回は１つ目の価値を「支出を管理できる」 = 「浪費を抑え貯金できる」 と捉え直す。\nまず前提としてこれを提供するために以下のようなグラフをユーザーが見れるようにするべき。\n前提を踏まえた機能案 1. 累積節約額 （ = 貯金額 ） の予測 上記に挙げたグラフを単純に回帰予測したグラフで十分\n現状と何も変わらずに将来に発生する利益を見るだけで人間は嬉しくなると思う。\nこれだけでこのアプリをみることが楽しくなると思う。少なくとも私はwealthnavi, meneyforward, bitflyerなど資産が記録されてるアプリが右肩上がりになっているのを見て嬉しくなるし意味もなくアプリを見てしまう。\n2. 節約プランの提案と違反した場合のアラート これは機械学習？というかデータ活用の見せ場になると思う。\n下図のように PlanA , PlanB という節約プランを提案し、ユーザーが違反した場合にアラートを出す。\nPlan毎には支出管理データをもとに、より安価な購買商品の提案、浪費を指摘などを行う。\nユーザーにとっては行動の結果が明白であり、それを実行するモチベーションが明快になる。\n機械学習が活用されることによる事業の展開の拡張 定期便サービスとの連携によるまとめ買いシェア 消耗品の相乗り買い（そういうサービスとの連携があるといい） 節約額（貯金額）のNISAや仮想通貨の自動投資 貯金額で旅行を提案したっていい（アフィリエイトが美味しい） 予想貯金額と実際の貯金額の相関をみたくなってデータを渡したくなるはず ユーザーのバジェットを知れるとやれることも増えるだろうと思う 所感 「節約が楽しくなる」感情にさせたら色々うまくいく 節約=貯金の構造が直感的にさせるUI/UXの設計はキモに思える 思考停止での節約活動をさせたらインフラになる（それ使ってないだけで損するよ？という風潮が作れたら良い） MLが創出する価値により、ユーザーがデータを差し出す構図は理想 支出の分類精度を上げよう！とかはわかりやすいが、事業の価値に連動するプランが欲しくなる それとこんなことを書いておいて、\n金をもらっていないのに何をしてるんだ、という気持ちもありつつこういうのを考えるのは楽しい その反面、こういうことを考えるだけの仕事があったら非常にやりたい ","permalink":"https://konumaru.org/202405/%E3%82%AB%E3%83%BC%E3%83%89%E4%BB%98%E3%81%8D%E5%AE%B6%E8%A8%88%E7%B0%BF%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%81%ABml%E3%82%92%E6%B4%BB%E7%94%A8%E3%81%97%E3%81%9F%E3%81%84%E3%81%A8%E8%A8%80%E3%82%8F%E3%82%8C%E3%81%A6/","summary":"\u003ch2 id=\"導入\"\u003e導入\u003c/h2\u003e\n\u003cp\u003eML Eng -\u0026gt; PdM というキャリアを進んでいる背景もあり、なんか機械学習を使ったいい感じの企画をしてくれよ、という話は多数耳にする。\u003c/p\u003e\n\u003cp\u003eとあるスカウトサービス経由でカード発行もやっているクレジットカード事業でそのような需要があることを耳にした。スカウトが来ただけなので働いてはいない。\u003c/p\u003e","title":"カード付き家計簿サービスにMLを活用したいと言われて"},{"content":"念願の仮想通貨botを運用開始できたので、ここまででやったことをざっとまとめる。\nTL;DR バックテストでは利益が出るbotを作れた それをGCPを使って実運用させられた CryptoBot開発をkaggleのような問題設定に落とし込めた 今後は強化学習モデルも取り入れていきたい Botを作ろうと思ったモチベーション NISAをやって放置してお金が増えるっていいなと気づいた 自分で資産運用Botを作ったらもっと楽に稼げるのでは API使えそうな仮想通貨でやってみよう と、安易に始めた。\nそういったモチベーションから始めたので、botのコンセプトは「放置して儲ける」とした。\nつまり、大きな価格変化を掴むような作戦ではなく、ちまちま金を増やす高頻度取引をするbotを作ることにした。\n無知なので、まずは本を読む 覚えている範囲で、以下の本を読んだ。\nファイナンス機械学習―金融市場分析を変える機械学習アルゴリズムの理論と実践 Pythonではじめるアルゴリズムトレーディング Pythonで学ぶ強化学習 日給300万円のSS級トレーダーが明かす botterのリアル 最後だけ毛色が違うが念のため読んでみた。\n特にファイナンス機械学習は、網羅的な知識をインプットできたので読んでおいてよかった。\nやったこと 雑に順番に書くとこんな感じ。\n価格データを定期的に取得する ランダムに取引を行うbotを作る 取引実績を評価する環境を作る 機械学習モデルを導入したbotを作る w/ ChatGPT ランダムエージェントとの比較を行う ローカルで実際に取引する 取引実績を毎日discordに配信 動くことを確認したら、クラウドで運用する 日々監視して心が落ち着かなくなる←ｲﾏｺｺ 実際に最後までやりきるには大体1~2か月くらい必要だった。 でも、CICD整えたり、TraderAgentの抽象クラスの考えたり、いろいろと自動化しながらやれてだいぶ楽しかった。\n最終的にはkaggleのような問題設定まで落とし込め多と思っていて、このあとの取引エージェントの改善はシンプルになってきたのでいろいろと試せると思う。\nシステム構成 システムはGCPで動いている。\nDBはお高いので節約のために、GCSで乗り切っており、 Traderが必要とするデータの取得が限界に来るまではこのままでいいかと思っている。\ngraph TD A[Subscriber] --\u003e|Get Price, Assets| B[Storage] C[Train ML Model in local] --\u003e |Upload ML Model| B B --\u003e|Get Price, Assets, ML Model| D[Trader] D --\u003e|Trade Order| E[Bitflyer] D --\u003e|Notify| F[Discord] 諸々思ったこと めちゃくちゃ簡易的なMLOpsを味わえた気分になった 実際には大規模データを使ったり、ML部分でマネージドサービスを使うことになるのだと想像できる 失っても大したことない金額とわかってても資産の上下に心動かされる 育てたやつがちゃんと働いたか気になる気持ち インフラ面 こういうちょっとした開発はGCPを使いたい 別で作ったGPTを使ったチャットbotもそうだが要らなくなったらプロジェクトごと消せるのが安心する Botについて 書籍やコンペサイトなど調べて、回帰モデルにしたが、強化学習で取引を決定するイメージを持てた 初手で強化学習をするにはおそらくデータ量が足りないうえに、内部的に持っている予測モデルのお気持ちもわからなかったとおもう。 kaggleとの違い お題に期日がない モデルの精度のお金が増えることに相関を持たせることが大変だとわかった（できので自分を褒めたい） モデルだけでなく周辺システム、クラウドサービスなどを含むも作れるの良い 時間のピタゴラスイッチは難しい データは1分おきで、Traderは5分おきで、実行に数分かかるから、、などなど。 時間の表現は今後統一しよう created_at_utc ","permalink":"https://konumaru.org/202403/%E4%BB%AE%E6%83%B3%E9%80%9A%E8%B2%A8bot%E3%81%A4%E3%81%8F%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9F/","summary":"\u003cp\u003e念願の仮想通貨botを運用開始できたので、ここまででやったことをざっとまとめる。\u003c/p\u003e\n\u003ch2 id=\"tldr\"\u003eTL;DR\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eバックテストでは利益が出るbotを作れた\u003c/li\u003e\n\u003cli\u003eそれをGCPを使って実運用させられた\u003c/li\u003e\n\u003cli\u003eCryptoBot開発をkaggleのような問題設定に落とし込めた\u003c/li\u003e\n\u003cli\u003e今後は強化学習モデルも取り入れていきたい\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"botを作ろうと思ったモチベーション\"\u003eBotを作ろうと思ったモチベーション\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eNISAをやって放置してお金が増えるっていいなと気づいた\u003c/li\u003e\n\u003cli\u003e自分で資産運用Botを作ったらもっと楽に稼げるのでは\u003c/li\u003e\n\u003cli\u003eAPI使えそうな仮想通貨でやってみよう\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eと、安易に始めた。\u003c/p\u003e","title":"仮想通貨botを作ってみた"},{"content":"CommonLitのコンペに参加したので振り返り\nコンペ概要 promptが与えられ、その中にはquestion, title, textがある。\nそれを生徒？が要約した内容に対し、content, wordingというスコアを着ける。\nコンペではそのcontent, wordingのスコアを予測する。\n取り組んだこと 詳細はリポジトリにある。 ここでは簡単にまとめる。\ndebertaでprompt_question, summary_textを入力にし、content, wordingを予測 上記の予測値とテキストを基にした特徴量を合わせて、XGB, LGBMで予測 XGB, LGBMの予測値をアンサンブル これでは全く上位には届かなかったので、上位解法見ていく。\n上位解法 2nd place solution debertaの入力値を'Think through this step by step : ' + prompt_question + [SEP] + 'Pay attention to the content and wording : ' + text + [SEP] + prompt_textとした prompt enginneringがこんなところでも・・・ SEPで囲まれた部分はmaskさせる 別コンペで学習させたモデルの予測値をつかった？ モデルの最大長は1280~2048 最終的には2048で学習？ GroupKFoldで0.4581 アンサンブル deverta-large mean pooling, lstm pooling deberata-base mean pooling, lstm pooling OpenAssistant/reward-model-deberta-v3-large-v2 mean pooling 3rd place solution prompt_question, summary_textを入力にし、content, wordingを予測 似ているサマリ文章同士で単語の置換を行った（これ思いついたのすごすぎ） 上記でData Augmentationをした deberta poolingには、cls tokenとmean poolintを使った token_type_idsを使って、prompt, question, textを区別した（token_type_idsってこういう使い方するんですね） max_lengthは1500 4th place solution 大量のモデルのアンサンブル deberta large, base layer freeze max_length 1500 ~ 868 poolings cls, mean GBDTを使ったアンサンブルを使っていたが、最終的にはcvが低かったのでアンサンブルはしなかった 自分の場合途中結果のcvを比較可能にしていなかったのでこれは反省点\u0026hellip; 5th place solution summary, question, title, prompt_textを使用 deberta largeとlgbmのアンサンブル deberta large max_length 1,536 最初の18layerをfreez content, wordingを同時に学習 lgbm public notebookをほぼ同じ（テキスト統計量を中心にしたものだろうか？） アンサンブルは加重平均 GroupKFold まとめ deberta largeを使う max lengthは1500程度と長めにする poolingをcls token, lstm, mean poolingなど多様性を持ったモデルをアンサンブルさせるのが効いた stackingよりもbest single modelを追い求める方が重要 と勝つために必要だったことを並べてみると、rtx3060とkaggle notebookだけでは戦えなかった気がする。\ndeberta largeは試したが、4fold学習しようとするとtimeoutになるし。。\n今回は縁がなかったコンペだった。早めに撤退するべきだった。 いいグラボを手に入れた時にまた頑張ろう。\n","permalink":"https://konumaru.org/202310/commonlit2023%E6%8C%AF%E3%82%8A%E8%BF%94%E3%82%8A/","summary":"\u003cp\u003eCommonLitのコンペに参加したので振り返り\u003c/p\u003e\n\u003ch2 id=\"コンペ概要\"\u003eコンペ概要\u003c/h2\u003e\n\u003cp\u003epromptが与えられ、その中にはquestion, title, textがある。\u003c/p\u003e\n\u003cp\u003eそれを生徒？が要約した内容に対し、content, wordingというスコアを着ける。\u003c/p\u003e","title":"CommonLit 2023 振り返り"},{"content":"PdMとしての経験が増え、管理するチームが10人を超えそうになったとき、マネージメントのコストが急増して大変になるのを防ぐ方法を試みました。この記事ではその時の経験を共有し、どのように問題を回避したかを記録として残しています。\none team one pizzaの思想のもの動いていたが上記の体制じゃお腹いっぱいになれない。 ということでどうやってチームを分割して、その動きを制御するのかを考えた結果になる。\n特に今回はスケーラブルな組織となることを目指している。\n導入 PdMの役割は事業目標にコミットしつつ、あらゆる手を使って製品のあるべきを模索することだと私は思っている。\nただし、会社によってはチームをマネージメントすることも求められることもあると思います。そう言ったときPdMの役割を果たしつつ、チームが最も機能できる状況を作り出すためにはどうすればいいのかを考えた。\n本来ならEM, Scrum Masterなどの役割の人たちと協力して組織形成をやりたいところだが、今回はそういった役割の人がいないものとする。\n組織体制の想定 大体こんな感じ↓\ngraph TD; A(Board) --\u003e B_Top(PO) B_Top(PO) --\u003e B(PdM) B_Top(PO) --\u003e B_dash(PdM) B(PdM) --\u003e T1(TeamA) B(PdM) --\u003e T2(TeamB) B(PdM) --\u003e T3(TeamC) PdMのポジションが自分であり、TeamA, TeamB, TeamCのPdMを兼任しているという想定。 またTeamが増えることを許容することでスケーラブルであると仮定している。\nTeamは3~5人程度の小規模なものを想定している。\nタスク管理の目的 タスク管理の目的は、このままいけば事業計画から逆算されたチームが到達するべき目標を完遂することができるか、そうでない場合そのチームの目標の方向修正が必要かを判断するためコミュニケーションを円滑にすることである。\n上記を達成するためPdMがチームや上位下位レイヤー間のコミュニケーションをする際に自分の頭で考え整理できるように情報を俯瞰できる必要がある。\nそのインプットがあることでタスクの進展や情報、見積りのアプデート、リソース配分の再検討などの提案をチームや上位レイヤーに提案することも可能になる。\n決して「進捗管理」をしたいのではなくPdM \u0026lt;-\u0026gt; Team間で事業目標を達成するために今何をするべきうかを一緒に考えるためのものと考えたい。\nここからはぼやきだが、そうしないとPdMが事業成長の限界値になってしまいかねないし、PdMは自己投資する時間を非常に取りにくい。（すごい人は違うのかもしれないけど）\n実践的なタスク管理方法 前提として以下を設ける。\n先半年から１年分くらいの事業計画はすでに存在するものとする 半期の事業目標の明確に決まっているものとする Teamの目標管理はOKRの形式で運営されている OKRについては、googleのre:workやOKR（オーケーアール）という書籍がわかりやすい。\nEpicの考え方については、AtlassianのブログやGitlabのブログが参考になった。j\n後述するがEpicはユーザーストーリー形式ではなく、機能単位で設定した。\nOKRとEpicの関係性のイメージは、KRはチャレンジングな目標数値が設定されており、EpicはそのKRを達成するための手段として設定される。\nEpicを完結させるためのSprintを計画する ざっと調べた感じ基本的にEpicという考え方はスクラムの文脈でしか語られてなかったので、チームはスクラムのような形式をとっているものとする。（そうでないならスクラムに変えよう。）\nEpicを完結させるためには、Epicを分割してSprint Backlog Itemを作成し、それを完結させることでEpicを完結させることができる。チームはこれを継続するだけで良くなる。\ngraph TD; A(Parent Epic) --\u003e Epic(Epic) Epic(Epic) --\u003e TaskA(Task) Epic(Epic) --\u003e TaskB(Task) Epic(Epic) --\u003e TaskC(Task) TaskA(Task) --\u003e BacklogItemA(Sprint Backlog Item) TaskC(Task) --\u003e BacklogItemB(Sprint Backlog Item) TaskC(Task) --\u003e BacklogItemC(Sprint Backlog Item) またEpicは以下のようにガントチャートにすることで体外的にスケジュールを公開することもでき、軌道修正するときに「EpicA_2が2週間ほど遅れそうですー」と言った時の影響範囲なども説明しやすい。\ngantt title Epic Timeline dateFormat YYYY-MM-DD section Parent_EpicA EpicA_1 :a1, 2025-04-01, 14d EpicA_2 :a2, after a1, 9d EpicA_3 :a3, after a2 , 42d section Parent_EpicB EpicB_1 :b1, 2025-04-01, 21d EpicB_2 :b2, after b1, 14d section Nan_Parent EpicC :c1, 2025-04-14, 7d EpicE :d, 2025-04-21, 14d EpicF :e, 2025-04-21, 28d また、Epicをユーザーストーリー形式にするか、機能名にするかという議論がある。\n個人的にはザッと情報を把握したいときには機能名のほうが見やすいので少なくともタイトルは機能名にしたい。機能名出ないにしても短く完結な表現をしてほしい。\nちなみに機能単位でロードマップを公開している企業をいくつか参考にした。\n参考：unreal engine, GitHub public roadmap, B4/3\nEpicの項目テンプレート Epicは大体これくらいの項目があると良いと思う。\n# タイトル ## 概要 （概要を記述してください） ## 背景 （何が問題であるか、なぜその問題が生じたか、なぜそのタスクが重要なのかなどの背景情報を記述してください） ## 関係者 （タスクに関係する人や組織を記述してください） ## 期間 （タスク完了にかかる見積もり期間を記述してください） ## タスク （epicを完了するために必要な具体的なタスクを記述してください） ## リスクや障害 （タスクを完了するために、リスクや障害物が発生する可能性やどのように対処するかを記述してください） ## 完了後の成果物 （タスクの完了後にどのような成果物が得られるかを記述してください） ## 成果指標 （Epicによって事業観点からの成果指標を記述してください） ## 期待する事業への影響 （新規事業の立ち上げ、売り上げ向上、PV数の向上、etc） ## 参考情報 （その他の情報や注釈があれば追加してください） まとめ 今のところ自分がチーム運営のキャパが溢れそうなときに取った対策をまとめた。\nまだまだEpicの粒度のバラツキや事業設定をOKRに落とし込むときの難しさなどを感じてはいるが、チームとPdMが認識を合わせたり少し将来の話をする難易度がグッと下がっているのを感じる。\nそう言った意味でもチームを管理や制御をしたいのではなくコミュニケーションを取りたいのだというスタンスを持つことが大事だと思った。\n","permalink":"https://konumaru.org/202308/%E3%82%B9%E3%82%B1%E3%83%BC%E3%83%AB%E3%81%99%E3%82%8B%E3%83%81%E3%83%BC%E3%83%A0%E3%81%A8%E5%8A%B9%E6%9E%9C%E7%9A%84%E3%81%AA%E3%82%B3%E3%83%9F%E3%83%A5%E3%83%8B%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3-pdm%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E3%82%BF%E3%82%B9%E3%82%AF%E7%AE%A1%E7%90%86/","summary":"\u003cp\u003ePdMとしての経験が増え、管理するチームが10人を超えそうになったとき、マネージメントのコストが急増して大変になるのを防ぐ方法を試みました。この記事ではその時の経験を共有し、どのように問題を回避したかを記録として残しています。\u003c/p\u003e","title":"スケールするチームと効果的なコミュニケーション: PdMのためのタスク管理"},{"content":"熊とワルツをという本を読み、リスク管理方法のフォーマットを作ったのでメモ用に記事にする。\nリスク管理の目的 「熊とワルツ」によるとリスクと利益は切っても切れない関係にある。らしい。\nリスクのあるプロジェクトだからこそ利益を産むし、自分の能力を伸ばすチャンスでもあると言っていて自分としても納得感がある。\nまあなので、何かおっきい仕事をするときに無視できない対象であり、乗り越えないといけないものなので管理しましょうね、くらいのモチベーションであると理解した。\nリスク管理の項目 リスク管理の方法として、以下をspreadsheetで管理したらいい感じだった。 何か思いついたら書き込み、誰かに説明したいときはここから参照できた。\nカラムの説明 説明 No リスク番号 Date 記入日 Title タイトル Research Document リスクに関する調査ドキュメントへのリンク Metric リスクを検知するための指標。精度よりも最も早く検知できることが望ましい Cost リスクが発生した場合、回避に要する概算相対工数 Exposure Rate (%) 現状わかっている主観的なリスク顕在化率 Is Exposed リスクが発生したか Action Type 軽減、対応、容認に分類する Action Plan 設定したMetricに従いリスクが発生したとき対策方針 Feature (Issue, crowi, etc) 該当機能にリスクに見合った価値があるかを比較するための参照リンクなど ","permalink":"https://konumaru.org/202308/%E3%83%AA%E3%82%B9%E3%82%AF%E7%AE%A1%E7%90%86%E3%81%AE%E6%96%B9%E6%B3%95/","summary":"\u003cp\u003e\u003ca href=\"https://www.amazon.co.jp/%E7%86%8A%E3%81%A8%E3%83%AF%E3%83%AB%E3%83%84%E3%82%92-%E3%83%AA%E3%82%B9%E3%82%AF%E3%82%92%E6%84%89%E3%81%97%E3%82%80%E3%83%97%E3%83%AD%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E7%AE%A1%E7%90%86-%E3%83%88%E3%83%A0%E3%83%BB%E3%83%87%E3%83%9E%E3%83%AB%E3%82%B3/dp/4822281868\"\u003e熊とワルツを\u003c/a\u003eという本を読み、リスク管理方法のフォーマットを作ったのでメモ用に記事にする。\u003c/p\u003e\n\u003ch2 id=\"リスク管理の目的\"\u003eリスク管理の目的\u003c/h2\u003e\n\u003cp\u003e「熊とワルツ」によると\u003ccode\u003eリスクと利益は切っても切れない関係にある。\u003c/code\u003eらしい。\u003c/p\u003e\n\u003cp\u003eリスクのあるプロジェクトだからこそ利益を産むし、自分の能力を伸ばすチャンスでもあると言っていて自分としても納得感がある。\u003c/p\u003e","title":"リスク管理の方法"},{"content":"コンペ概要 hogehoge\n解法 1st code GBDT + NNのアンサンブル XGBoost Treeliteで推論高速化 1dcnn transformerを試したが、同じスコア+軽量だったため1dcnnを採用 閾値は0.625で固定 閾値は個別に設定するとモデルの堅牢性が低かった 特徴量の数は、各level_groupで 663、1993、3734 indexをソートしたものと、元の順序の両方のモデルを作成 cv=0.705 2nd 単一のLightGBMで予測 level_groupごとにモデルを分けていない 5-fold cvで評価、予測用に全データでモデルを学習 特徴量生成にはnumba, Cを使った level=1の回答に費やした時間？が効いた 特徴量は1,296個 閾値は0.63で固定 3rd levelごとにモデルを学習（18個の2値分類モデル） GBDT + NNのアンサンブル Catboost * 2, xgb * 2 transformer + lstm ローデータをsession_idごとのindexでソート 特徴量の数は、1,000個、2,000個、2,400個 前のlevel_groupからの経過時間 過去質問の予測確率（自分の場合は効かなかった） permutation importanceで特徴量選択 cv=0.702 4th Transformer, XGB, Catboostのアンサンブル 3 seed, 5 fold 線形モデルでアンサンブル indexでソート後、hover行を削除し再度indexを作成した level_groupごとにモデルを学習しているが、nnモデルの共通部分の定義がうまい cv=0.704 異なる閾値（0.60, 0.62, 0.64）の最終提出３つを選んだ 結果的には0.61が最もprivate scoreが高かった 7th level_groupごとにモデルを学習 予測時間短縮のため、levelごとにモデルを分割しなかった 評価時はcv分割したが、推論用には全データで学習したモデルを使用 特徴量 集約キーはlevel、name、event_name、room_fqid、fqid、text 集約キーごとの前のイベントとの時間差、カウント event_name=notification_clickのレコードが重要だった（？） 集約キーの組み合わせが多いため、出現回数が低いものは除外した モデリング 高い学習率(0.1)で学習し、特徴量重要度(gain)が低いものを除外 低い学習率(0.02)で再度学習 cv=0.7034 閾値は0.625で固定 金圏との差分 特徴量の数が足りなかった Leakを考慮した特徴量重要度を用いた特徴量選択ができなかった 全foldで特徴量重要度を平均して選択するのはダメ 検証用データの特徴量重要度を知ってしまう状態になってしまう foldごとに特徴量重要度を平均し、評価する必要があった jackさんの解法では、最後にcvを切らず全データを使った学習をしているがそのときはfoldごとの特徴量重要度を平均したものを使っている 閾値を固定していない GBDT + NNのアンサンブルを試していない ","permalink":"https://konumaru.org/202307/psp%E3%82%B3%E3%83%B3%E3%83%9A%E6%8C%AF%E3%82%8A%E8%BF%94%E3%82%8A/","summary":"\u003ch2 id=\"コンペ概要\"\u003eコンペ概要\u003c/h2\u003e\n\u003cp\u003ehogehoge\u003c/p\u003e\n\u003ch2 id=\"解法\"\u003e解法\u003c/h2\u003e\n\u003ch3 id=\"1st\"\u003e\u003ca href=\"https://www.kaggle.com/competitions/predict-student-performance-from-game-play/discussion/420217\"\u003e1st\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.kaggle.com/competitions/predict-student-performance-from-game-play/discussion/420332\"\u003ecode\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eGBDT + NNのアンサンブル\n\u003cul\u003e\n\u003cli\u003eXGBoost\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/dmlc/treelite\"\u003eTreelite\u003c/a\u003eで推論高速化\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e1dcnn\n\u003cul\u003e\n\u003cli\u003etransformerを試したが、同じスコア+軽量だったため1dcnnを採用\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e閾値は0.625で固定\n\u003cul\u003e\n\u003cli\u003e閾値は個別に設定するとモデルの堅牢性が低かった\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e特徴量の数は、各level_groupで 663、1993、3734\u003c/li\u003e\n\u003cli\u003eindexをソートしたものと、元の順序の両方のモデルを作成\u003c/li\u003e\n\u003cli\u003ecv=0.705\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"2nd\"\u003e\u003ca href=\"https://www.kaggle.com/competitions/predict-student-performance-from-game-play/discussion/424329\"\u003e2nd\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e単一のLightGBMで予測\n\u003cul\u003e\n\u003cli\u003elevel_groupごとにモデルを分けていない\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e5-fold cvで評価、予測用に全データでモデルを学習\u003c/li\u003e\n\u003cli\u003e特徴量生成にはnumba, Cを使った\n\u003cul\u003e\n\u003cli\u003elevel=1の回答に費やした時間？が効いた\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e特徴量は1,296個\u003c/li\u003e\n\u003cli\u003e閾値は0.63で固定\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"3rd\"\u003e\u003ca href=\"https://www.kaggle.com/competitions/predict-student-performance-from-game-play/discussion/420235\"\u003e3rd\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003elevelごとにモデルを学習（18個の2値分類モデル）\u003c/li\u003e\n\u003cli\u003eGBDT + NNのアンサンブル\n\u003cul\u003e\n\u003cli\u003eCatboost * 2, xgb * 2\u003c/li\u003e\n\u003cli\u003etransformer + lstm\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eローデータをsession_idごとの\u003ccode\u003eindex\u003c/code\u003eでソート\u003c/li\u003e\n\u003cli\u003e特徴量の数は、1,000個、2,000個、2,400個\n\u003cul\u003e\n\u003cli\u003e前のlevel_groupからの経過時間\u003c/li\u003e\n\u003cli\u003e過去質問の予測確率（自分の場合は効かなかった）\u003c/li\u003e\n\u003cli\u003epermutation importanceで特徴量選択\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ecv=0.702\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"4th\"\u003e\u003ca href=\"https://www.kaggle.com/competitions/predict-student-performance-from-game-play/discussion/420349\"\u003e4th\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eTransformer, XGB, Catboostのアンサンブル\n\u003cul\u003e\n\u003cli\u003e3 seed, 5 fold\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e線形モデルでアンサンブル\u003c/li\u003e\n\u003cli\u003eindexでソート後、hover行を削除し再度indexを作成した\u003c/li\u003e\n\u003cli\u003elevel_groupごとにモデルを学習しているが、nnモデルの共通部分の定義がうまい\u003c/li\u003e\n\u003cli\u003ecv=0.704\u003c/li\u003e\n\u003cli\u003e異なる閾値（0.60, 0.62, 0.64）の最終提出３つを選んだ\n\u003cul\u003e\n\u003cli\u003e結果的には0.61が最もprivate scoreが高かった\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"7th\"\u003e\u003ca href=\"https://www.kaggle.com/competitions/predict-student-performance-from-game-play/discussion/420119\"\u003e7th\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003elevel_groupごとにモデルを学習\n\u003cul\u003e\n\u003cli\u003e予測時間短縮のため、levelごとにモデルを分割しなかった\u003c/li\u003e\n\u003cli\u003e評価時はcv分割したが、推論用には全データで学習したモデルを使用\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e特徴量\n\u003cul\u003e\n\u003cli\u003e集約キーはlevel、name、event_name、room_fqid、fqid、text\u003c/li\u003e\n\u003cli\u003e集約キーごとの前のイベントとの時間差、カウント\u003c/li\u003e\n\u003cli\u003eevent_name=notification_clickのレコードが重要だった（？）\u003c/li\u003e\n\u003cli\u003e集約キーの組み合わせが多いため、出現回数が低いものは除外した\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eモデリング\n\u003cul\u003e\n\u003cli\u003e高い学習率(0.1)で学習し、特徴量重要度(gain)が低いものを除外\u003c/li\u003e\n\u003cli\u003e低い学習率(0.02)で再度学習\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ecv=0.7034\u003c/li\u003e\n\u003cli\u003e閾値は0.625で固定\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"金圏との差分\"\u003e金圏との差分\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e特徴量の数が足りなかった\u003c/li\u003e\n\u003cli\u003eLeakを考慮した特徴量重要度を用いた特徴量選択ができなかった\n\u003cul\u003e\n\u003cli\u003e全foldで特徴量重要度を平均して選択するのはダメ\n\u003cul\u003e\n\u003cli\u003e検証用データの特徴量重要度を知ってしまう状態になってしまう\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003efoldごとに特徴量重要度を平均し、評価する必要があった\u003c/li\u003e\n\u003cli\u003ejackさんの解法では、最後にcvを切らず全データを使った学習をしているがそのときはfoldごとの特徴量重要度を平均したものを使っている\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e閾値を固定していない\u003c/li\u003e\n\u003cli\u003eGBDT + NNのアンサンブルを試していない\u003c/li\u003e\n\u003c/ul\u003e","title":"PSPコンペ振り返り"},{"content":"コンペ概要 コンペページはこことは\nドイツ最大級のオンラインショップOTTOを題材に特定のユーザがどの商品に対し、クリック、カート追加、注文するかを予測する。\nデータはアイテム数180万、ユーザ数1200万人、インタラクション数2.2億が与えられる。これらのデータは４週間のインタラクション履歴からなる。 3週間分をtrain, 残り1週間をtestとして扱う。また、train, testでユーザの重複はない。\n評価は、各インタラクション（click, cart, order）ごとにRecall@20の重み付き平均和で計算される。\n解法の概要 Model Candidate Generation (Recall) Rerank CV Strategy 5%のユーザを使う 上位解法 1st place solution Candidate Generation NNでEmbeddingを作成 session embedding aid embedding 学習時は上記を使って、positive, negativeサンプリングをそれぞれ行いRerankerが学習するデータを選出 cos similiarityが (avg + min) / 2 以上のものをpositiveとする？ Reranker LGBMRanker Feature session * aidを使ったcandi まとめ ","permalink":"https://konumaru.org/202305/kaggle-otto%E3%82%B3%E3%83%B3%E3%83%9A%E8%A7%A3%E6%B3%95%E8%AA%BF%E6%9F%BB/","summary":"\u003ch2 id=\"コンペ概要\"\u003eコンペ概要\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://www.kaggle.com/competitions/otto-recommender-system/overview\"\u003eコンペページはここ\u003c/a\u003eとは\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.otto.de/\"\u003eドイツ最大級のオンラインショップOTTO\u003c/a\u003eを題材に特定のユーザがどの商品に対し、クリック、カート追加、注文するかを予測する。\u003c/p\u003e\n\u003cp\u003eデータはアイテム数180万、ユーザ数1200万人、インタラクション数2.2億が与えられる。これらのデータは４週間のインタラクション履歴からなる。\n3週間分をtrain, 残り1週間をtestとして扱う。また、train, testでユーザの重複はない。\u003c/p\u003e","title":"kaggle OTTOコンペ解法調査"},{"content":"何を作ろうと思ったのか ひとことで言うと「マッチングアプリに変わる恋愛シュミレーションAI」を作りたかった。\nChatGPTを使ってみたところかなり自然に会話をしてくれたので、まるで人と話しているかに感じることができた。 それを受けてプロンプトで人格を定義して、シュミレーションゲーム風にして人と話すことを目的にしているマッチングアプリユーザをリアルの人と関わることによるストレスから解放できないかと思いつくってみることにした。\nついでにStripeを使って有料化しようと思ったが、そこまでの品質にはならなかった。\n出来上がったもの 詳細はGithubを参照してください。\n正直人と話ている状態とはほど遠く、実験的に作った４択形式のインターフェースが楽ではあったがリアルから離れすぎてしまった。\nアーキテクチャはこんな感じ\nプロンプトエンジニアリングの難しさ GPT3.5だったのもあったが、出力を安定させるのが非常に難しかった。\njsonで出力されることが担保されるならMessaging APIで提供されているクイックリプライを使いたかった\nまた、口調を人っぽくするだけなら簡単だったがなんとも言えない会話の成立のしなさが解決できなかった。 必ず返答をしてくれるのだが、会話が堂々巡りしてしまったらだらだらとやり取りが続いてしまう。\nあとは動作テストをChatGPTでやっていたが、実際にはLangchianを使って実装している。 今回はやらなかったが、Langchianをつかうならいくつかの役割にBotを分離させて並列に複数の処理をさせることで\n記憶の単純化 レスポンス速度の向上 プロンプトの簡略化 などを期待できたかもしれないと思った。\nLINEというインターフェースの良さ 簡単にいくつか上げると\n簡単にリッチなUIが使える 使い慣れているインターフェースなので受け入れられやすい 友達と飲んでいる時にちょっとこれつかってみてよ。がやりやすかった GPTのデメリットであるレスポンスの遅さがLINEだと意外と自然 とはいえ、連投とかされると困った LINEのデメリット 唯一デメリットは、動作テストのしにくさだった。\nngrokでローカルにエンドポイントを立てる LINE Messaging APIにエンドポイントを再登録 function frameworkでCloud Functionのローカルサーバを立てる 手元のデバイスでLINE使って動作テスト などやっている間にデプロイしてしまったほうが楽だったりした。\n完成までの反省点 遅い。シンプルに納得がいくところまで作り終えるのが遅かった。 動かすだけなら一晩で作ることができきたが、プロンプトエンジニアリングが難しかった。\nインフラ面では、始めにタイムアウトを気にしてCloud Runを使っていたが、結果的にはCloud Functionで動かすことにしてことで開発が二度手間になった。\n開発過程で取り組んで良かったこと 以下の企画書を書いたのはよかった。 目的決めて、期日、撤退ラインなどを事前に決めておくのは本当によかった。\n# 企画書 ## サービス内容 ## 証明したいこと ## 実現可能性 ## リリース目標 ## インフラ ## 実装方針 ## お金回り ## 撤退ライン ## 広める方法 ","permalink":"https://konumaru.org/202305/gpt-3.5%E3%81%A7%E4%BD%9C%E3%81%A3%E3%81%9F%E6%81%8B%E6%84%9B%E3%82%B7%E3%83%A5%E3%83%9F%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3ai-chatbot/","summary":"\u003ch2 id=\"何を作ろうと思ったのか\"\u003e何を作ろうと思ったのか\u003c/h2\u003e\n\u003cp\u003eひとことで言うと「マッチングアプリに変わる恋愛シュミレーションAI」を作りたかった。\u003c/p\u003e\n\u003cp\u003eChatGPTを使ってみたところかなり自然に会話をしてくれたので、まるで人と話しているかに感じることができた。\nそれを受けてプロンプトで人格を定義して、シュミレーションゲーム風にして人と話すことを目的にしているマッチングアプリユーザをリアルの人と関わることによるストレスから解放できないかと思いつくってみることにした。\u003c/p\u003e","title":"GPT-3.5で作った恋愛シュミレーションAI ChatBot"},{"content":"概要 教師なし学習を使った異常検知をやってみたいと思い 、Pythonではじめる教師なし学習を読んでいたらちょうど いいお題があったのでやってみることにした\nここではサンプルデータを対象にPCAを使った異常検知を行う\nなぜ検出できるのかという理論的な内容についてはここでは触れない。（というかわかっ てない）\nアプローチ PCAについて はこのPDFが 詳しく書いてあった\n前提として、なんらかの理由で訓練データに異常標本が混ざっており、教示データを用意 できないこととする。\n（専門家の方には怒られてしまう表現なのは重々承知で、）\n上記の資料ではPCAは以下のように説明されている\n多次元データのもつ情報をできるだけ損わずに低次元空間に情報を縮約する方法\nこの性質を使って、\n異常標本が混ざっている多次元データ 1のデータをPCAで次元圧縮し、固有値ベクトルを取得 1と2のデータを使って一度次元圧縮し、復元した逆変換データを作る 元データと逆変換データの差分が大きい値を異常標本として検出する 上記のような処理をすることで、一度PCAをした際に正常なデータの方が多いことが想定されるため、Fitされるベクトルが正常標本に偏りと思われる\nその性質を利用して、逆変換をした際に異常標本は正常データに偏って変換されるため元データとの差分が正常標本よりも大きくなると考えられる\nPCA を使った異常検知の実装 実装したscriptはこちら\n２値分類のサンプルデータを生成 from pyod.utils.data import generate_data X_train, _, y_train, _ = generate_data( n_train=2000, n_test=0, contamination=0.1, # percentage of outliers random_state=42, ) X_trainとy_trainの中身\nX_train: (2000, 2) [[6.43365854 5.5091683 ] [5.04469788 7.70806466] [5.92453568 5.25921966] [5.29399075 5.67126197] [5.61509076 6.1309285 ]] y_train: (2000,) [0. 0. 0. 0. 0.] 以下は入力データの分布の画像だが、特徴量を見ても別のデータとして視認できそう PCA を使ってデータを逆変換 import numpy as np from sklearn.decomposition import PCA def fit_and_inverse(data: np.ndarray, n_components: int = 2): pca = PCA(n_components=n_components) reduced = pca.fit_transform(data) inverse = pca.inverse_transform(reduced) return inverse raw = X_train.copy() inv = fit_and_inverse(raw) 元データと逆変換データの差分から閾値を決定 mse = ((raw - inv) ** 2).mean(axis=1) # NOTE: # 今回は10%が異常データとして生成してるので90percentileで閾値を設ける # 実際には想定される異常値の割合や期待する再現率などから設定すると考えられる threshold = np.percentile(mse, 90) 以下の画像が標本ごとのMSEの分布と閾値になる\n分布からはこれが良い閾値なのかはわかりにくいと思った\n分類結果 precision recall f1-score support 1.0 0.91 0.70 0.79 200 0.0 0.97 0.99 0.98 1800 まとめ PCAを使った異常検知の手法ということで、ラベルデータがない環境下でも取れる手段としていい知見になった。\n使っている手法がPCAになるのでカテゴリカルデータや元データの次元数が多い時などさまざまな場面では制約になることがあるのかなあとか思った。\n","permalink":"https://konumaru.org/202210/pca%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E7%95%B0%E5%B8%B8%E6%A4%9C%E7%9F%A5/","summary":"\u003ch2 id=\"概要\"\u003e概要\u003c/h2\u003e\n\u003cp\u003e教師なし学習を使った異常検知をやってみたいと思い\n、\u003ca href=\"https://amzn.to/3eM9dfF\"\u003ePythonではじめる教師なし学習\u003c/a\u003eを読んでいたらちょうど\nいいお題があったのでやってみることにした\u003c/p\u003e\n\u003cp\u003eここではサンプルデータを対象にPCAを使った異常検知を行う\u003c/p\u003e","title":"PCAを使った異常検知"},{"content":"コンペ概要 ざっくりの概要はサッカーの試合動画(45min * 2) から特定のフレームで Challenge, Play, Throwin の３つのイベントを予測するというもの\n（合っているか不安だが、）サッカー業界の事情としては、ユース、プロ、セミプロなど は手厚い指導を受けられるが、それ以外のプレイヤーは質の良い指導を受けられるほど人 材は充実していない。\nこれを画像処理の技術によって試合中の選手の活動状況を把握することで少ない人的コス トで選手に有益なアドバイスをできないか、という取り組み。\n評価指標 公式の説明 はここ\nsubmission file は以下 Columns を必要とした csv ファイルを提出する。\nvideo_id: 動画の識別子 time: event が発生した動画内の時間 event: challenge, play, throwin の内、発生したイベントを１つ score: イベントが発生した確率（後に Average Precision を算出するときに使う） このコンペの評価を簡単に説明すると以下のような計算を行います\n各 event について Average Precision を計算 その際に下記の Tolerances (許容度)に従い、正解ラベルとの time の誤差以内であれ ば正解とする つまり１つのラベルで time の誤差０であれば５回予測できたとする 最後に３つの event の Average Precision の平均値を評価指標とする # Tolerances Challenge: [ 0.30, 0.40, 0.50, 0.60, 0.70 ] Play: [ 0.15, 0.20, 0.25, 0.30, 0.35 ] Throw-In: [ 0.15, 0.20, 0.25, 0.30, 0.35 ] 本コンペで難しいと感じた部分 データが動画 動画によってカメラの画角が捉えてる範囲が異なる 客席も映像に入ってる コードコンペだったので CPU/GPU 共に 9 時間の制限がある Discussion の情報が乏しい（画像処理の経験が浅いのでつらかった） （ここの言語化ができてない時点で負けている感がある\u0026hellip;.）\n自分が取り組んだ内容 当時のRepository\n(Private にしていると思うので見れません。)\nYolov7 で ball, person の x,y,conf を取得 時系列テーブルデータとして特徴量エンジニアリング ball の xy 座標と confidence 予測対象フレームの-20~20 のフレーム前後の ball の xy 座標と confidence 予測対象フレームの-20~20 のフレームで rolling した ball の xy 座標と confidence の統計量 予測対象フレームの-20~20 のフレーム間で ball が移動したベクトルの内積と角度 検出された person 全員の座標の統計量 XGBoost で学習、損失関数は LogLoss Group=game_id(video_id から前半後半を統合), k=3 の GroupKFold で評価 結果は、ローカルで 0.2 と戦えるスコア出なかった\nplay だけは 0.7 近く予測できたが、challenge と throwin は 0.02 程度だった\n上位解法 1st Solution 4 つの動画を固定で検証用に使った 1024*1024 のグレースケールで前後のフレームを使った 3 チャンネルの画像を使用 処理速度を考慮 efficientnetv2_b0, efficientnetv2_b1 を使用 3dcnn は pooling 前の最終ブロックと最後の畳み込み層のみ 小さいデータセットに対して過学習することはすぐに分かった 損失関数は３つのカラムで BCE ダミーデータはどうしてたんだろう？ マルチスレッド化して推論を高速化 １つの video で 25 min であり、モデルを 2 つしようしたので 50 min 最終的には全体で 5 hours 2nd Solution オプティカルフロー オプティカルフローを予測？ RAFT というアイデアを使ってる ボールの検出 対象フレームの RGB、前後のオプティカルフローのブレームの RGB の合計 9channel を使用 検出された Ball のヒートマップの内、上位 10 に厳選 ボール軌道のコスト最小化 N フレームを対象にボール検出で厳選された 10 の ball から軌道を考慮すると尤も らしいものを選定 イベント分類 ボール周辺の画像をトリミングしたものを使用 2D CNN + Ball 軌道特徴量 -\u0026gt; 1D CNN -\u0026gt; 4 Event Class Prediction（短期予測？） Stacking 51 フレームの簡易的な特徴量から中間の７フレームを対象に予測（長期予測？） 後処理 Play\u0026amp;Pass については７フレームの内？予測値が peek の time を採用 Challenge についてはノイズが多かったので予測値にガウシフィルターを適用後同様 の処理でイベント発生 time を選定 3rd Solution EfficientNet + Simple 1D UNet input=(1, 64, 3, 360, 640) 前後に 64 フレームも使ってる！？ 64 フレーム中で score が peek のフレームを採用 Backbone をフリーズさせることで学習を高速化 ボール検出の pretraining そのまま学習するとオーバーフィットする ボールの位置を教えることで解決 ボールの位置は自分でアノテーションした（自分でアノテーションは頭になかった \u0026hellip;） ラベルデータの加工 正解ラベルを中心に緩やかに正解にする(0~1 のグラデーションを持たせる) 正解ラベルの周辺フレームは event に近い動きをしているはずなのでそのニュア ンスを表現することでモデルの FalesNegative を抑制してる？ Augmentation RandomHorizontalFlip, RandomRotation, ColorJitter, etc Loss Function は、Focal Loss Challenge と Throwin はデータが少ないので weight を設定することで調整 推論 imutilsで video のデコードを MultiTread 化 これをつかって動画読み込みむだけで早くなるってことなのか？ 後処理 NSM の閾値に[12, 6, 6] for [challenge, play, throwin]と言ってるがどういう ことなのだろう 5th Solution グレースケール、size=(1024,576), crop_center(960,512) 前フレームとの差 前後 5 フレームの effecientnet_b1 による 3 クラス分類 5 モデルのアンサンブル(CV したモデル) ラベルデザイン σ=20 フレームのガウス分布 前後 20 フレームについてガウス分布にしたがって緩やかにラベルを付与したって ことだろうか 上位を取るために そもそも NN を使うということ Efficientnet, UNet について要復習 入力の３次元は RGB の color channel だけでなく、時間軸にも使える 検証データを固定した試行錯誤の時間の削減 最初は画像サイズを小さくなども ガウス分布を使ったラベルの重みづけ 動画読み込みの並列化による推論の高速化 既存のライブラリやモジュールを活用したスタートラインを高く持つ志 諸刃の剣かもしれんが、少なくとも画像コンペにおいては\u0026hellip;？ お気持ち 「知っていて出来なかったこと」と「知らなくて出来なかったこと」があったように感じ た\n知っていてできなかったことは、今回の問題と紐づかなかったのでどうすればよいのか難 しいが、少なくとも知らなかったことは知っているに変えたい\n","permalink":"https://konumaru.org/202210/kaggle%E3%82%B3%E3%83%B3%E3%83%9Adfl%E5%8F%8D%E7%9C%81%E4%BC%9A/","summary":"\u003ch2 id=\"コンペ概要\"\u003eコンペ概要\u003c/h2\u003e\n\u003cp\u003eざっくりの概要はサッカーの試合動画(45min * 2) から特定のフレームで Challenge,\nPlay, Throwin の３つのイベントを予測するというもの\u003c/p\u003e\n\u003cp\u003e（合っているか不安だが、）サッカー業界の事情としては、ユース、プロ、セミプロなど\nは手厚い指導を受けられるが、それ以外のプレイヤーは質の良い指導を受けられるほど人\n材は充実していない。\u003c/p\u003e","title":"kaggleコンペ DFL反省会"},{"content":"これを読んで得られるもの PM, Desingner, Developerの間で、何を、何故作るのかの共通認識を作るための手段\nPRD とは 「プロダクトマネージャー本人も含めて、常に立ち返るべき方針」をドキュメントにしたもの ブレの無い意思決定をするため 開発終盤に入り期日も近づいた時の取捨選択を判断する基準 「何を」を説明することを目的にしており、「どのように」は説明しない より詳しい内容については及川さんというかたが公開されているはじめてのPRDがとても参考になる\nPRD のテンプレート 以下はProduct Huntのものを参照している。\n合わせてnoteに投稿されていた記事も非常に参考になった。\n# Title ## Intro \u0026amp; Goal 私たちの目的は、 XXXをYYYにとってZZZなツールにすることです。 XXXはhogehogeなツールになります。 ## Product Vision ## Who\u0026#39;s it for? ｜誰のためにあるか 1. ユーザー - XXXを利用するユーザー ## Why build it?｜なぜ創るか ## What is it?｜どういうものか ### Glossary ｜用語 ### User Types ### UI/Screens/Functionalities ｜ UI/画面/機能 ## Brainstormed Ideas ｜その他アイデア ## Competitors \u0026amp; Product Inspiration ｜競合 ## Seeding Users \u0026amp; Content ｜初期ユーザーと獲得戦略 ## Mockups ## Tech Notes PRD を書くステップ PRDの作成ステップについては以下の記事がとても参考になった。\nProduct Templates: Product Requirements Document (PRD)\n素案を書く Good Ideaをプライベートドキュメントに書いてみる 言語化の過程で自らが間違っていたことに気づくかもしれません Backgroud, Objective, metricsは最低限欲しい さらに、ユーザーが利用するシナリオ、主要機能を言語化できると素晴らしい 上長の承認を得る 上司の考えやフィードバックを入手するのが目的 自分よりもドメイン知識を豊富に持っている人の意見は貴重です また情報の透明性にも繋がります デザイナーと共有 エンジニアリングについて語る前にユーザーに触れさせるのが懸命です デザイナーの意見を積極的に仕様に反映させましょう エンジニアと共有 （理想的には）デザイナーとエンジニアのリーダーと PRD を共有し、フィードバックを得ます 技術的に実現可能なものを見つけ、大まかな時間・難易度の見積りを行う プロダクトチーム全体に共有 この時点で正式に会社のwikiにPRDを移動 チームから得た質問や情報をPRDに記録していきます プロダクトチームから良きアイデアが出た場合、初期に実現しないとしてもここにメモします 会社に共有 必要に応じて、プレゼンテーションの材料とすることができます ","permalink":"https://konumaru.org/202209/prd---what%E3%82%92%E6%B1%BA%E3%82%81%E3%82%8B%E3%81%9F%E3%82%81%E3%81%AE%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88/","summary":"\u003ch2 id=\"これを読んで得られるもの\"\u003eこれを読んで得られるもの\u003c/h2\u003e\n\u003cp\u003ePM, Desingner, Developerの間で、何を、何故作るのかの共通認識を作るための手段\u003c/p\u003e\n\u003ch2 id=\"prd-とは\"\u003ePRD とは\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e「プロダクトマネージャー本人も含めて、常に立ち返るべき方針」をドキュメントにしたもの\u003c/li\u003e\n\u003cli\u003eブレの無い意思決定をするため\u003c/li\u003e\n\u003cli\u003e開発終盤に入り期日も近づいた時の取捨選択を判断する基準\u003c/li\u003e\n\u003cli\u003e「何を」を説明することを目的にしており、「どのように」は説明しない\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eより詳しい内容については及川さんというかたが公開されている\u003ca href=\"https://www.slideshare.net/takoratta/prd-192302662\"\u003eはじめてのPRD\u003c/a\u003eがとても参考になる\u003c/p\u003e","title":"PRD - Whatを決めるためのドキュメント"},{"content":"経緯 諸事情により、PC を新しくしたところ hugo server がローカルで起動しなくなった よく確認せずに Github Actions へビルドしたら CI は通過したのでローカル環境の問題だと推測した エラーメッセージ hogehoge\n❯ hugo server -D Start building sites … hugo v0.102.3+extended darwin/amd64 BuildDate=unknown WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for layout \u0026#34;archives\u0026#34; for kind \u0026#34;page\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;term\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;term\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;page\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;term\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;term\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;page\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;term\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;home\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for layout \u0026#34;search\u0026#34; for kind \u0026#34;page\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;taxonomy\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination 対応 原因は、サブモジュールを初期化\u0026amp;更新する必要があった\n\u0026gt; git submodule update --init --recursive 更新するだけでなく、初期化が必要な部分でつまづいた。\n","permalink":"https://konumaru.org/202209/hugo-%E3%83%93%E3%83%AB%E3%83%89%E3%82%A8%E3%83%A9%E3%83%BC%E5%AF%BE%E5%BF%9C/","summary":"\u003ch2 id=\"経緯\"\u003e経緯\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e諸事情により、PC を新しくしたところ hugo server がローカルで起動しなくなった\u003c/li\u003e\n\u003cli\u003eよく確認せずに Github Actions へビルドしたら CI は通過したのでローカル環境の問題だと推測した\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"エラーメッセージ\"\u003eエラーメッセージ\u003c/h2\u003e\n\u003cp\u003ehogehoge\u003c/p\u003e","title":"202209時点で起きたHugoビルドエラー対応"},{"content":"「クリストファー・アレクサンダーの思考の軌跡 - デザイン行為の意味を問う」を読んだ感想をまとめる\n形は機能に従う、機能は形に従うのではない 「形は機能に従う」\nこれがこの本の中で最も重要だった言葉だと感じました。\n様々なニーズを満たすものの形は、そのニーズを満たすような機能が先だって定められ、その機能を満たす形がおのずと決まる。ということを言っている。\nデザイナーと自然科学者の対比 本書では扇風機の説明の仕方を例にその違いを対比していた。\nデザイナー観点での扇風機の説明\n扇風機はその前にいる人を涼しくするという機能を持っている\nクリストファー・アレクサンダーの思考の軌跡 - デザイン行為の意味を問う | 長坂 一郎 (著)\n自然科学者観点での扇風機の説明\n扇風機は羽を回転させて（最近は翅のないものもあるが）、一定の風速の空気の流れを発生させるという機能を持っている\nクリストファー・アレクサンダーの思考の軌跡 - デザイン行為の意味を問う | 長坂 一郎 (著)\nこの２つの「機能」の説明は全く異なり、デザイナーの観点からは扇風機が作られた目的が説明されている。\n自然科学者の観点からでは「機能は形に従う」説明になっている。機能に先だって形が存在していることになる。\n例えば、「キリンの高いところにある葉を食べる（機能）から首が長い（形）のだ」のようになる。 （キリンは高いところにしか葉がないから首が長くなったのではなかっただろうか。）\nこの「機能」の捉え方がデザインにとって最も根底にあることだと思われる。\nデザイナーにとっては、形に先だって機能があるという考え方によって再現あるよいデザインをすることができるのではないかとこの本では言われている。\nデザイナーの仕事 デザイナーの仕事は、この「機能」が目的としている「ニーズ」を定義し、分析することにある。（と読み取れた。)\nここでの「ニーズ」は～を求めている。ではなく、～をしようとしている。などの傾向のことを言う。\n本書では「ニーズ」＝「人々がしようとすること」と概念を置き換えている。\nデザイナーはこの「人々がしようとすること」が何らかの理由で実行できないとき、それを様々なモノの粒度や関係性を変えることで、ユーザが実行できる状況を作り出すことが仕事になる。\nこの目指す状況の違いに特定の人、デザイナーならではの個性が現れるのだと思われる。\nオーダーメイドっていいもんなんだな、 この本を読んでオーダーメイドというは、このプロセスをひとり占めできるのだからそれは贅沢なものなのだと気づいた。\n他の誰のためのものでもなく、自分だけのためにニーズを分析して、形を作る。\nこのプロセスを経て作られたものがいいものでない訳がない。\n","permalink":"https://konumaru.org/202207/%E5%BD%A2%E3%81%AF%E6%A9%9F%E8%83%BD%E3%81%AB%E5%BE%93%E3%81%86/","summary":"\u003cp\u003e\u003ca href=\"https://amzn.to/3oh6CeM\"\u003e「クリストファー・アレクサンダーの思考の軌跡 - デザイン行為の意味を問う」\u003c/a\u003eを読んだ感想をまとめる\u003c/p\u003e\n\u003ch2 id=\"形は機能に従う機能は形に従うのではない\"\u003e形は機能に従う、機能は形に従うのではない\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e「形は機能に従う」\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eこれがこの本の中で最も重要だった言葉だと感じました。\u003c/p\u003e\n\u003cp\u003e様々なニーズを満たすものの形は、そのニーズを満たすような機能が先だって定められ、その機能を満たす形がおのずと決まる。ということを言っている。\u003c/p\u003e","title":"形は機能に従う"},{"content":"目標設定のフレームワークとして OKR を採用することにしたので、OKR 導入のために必要な基礎的な知識をまとめる。\nOKR とは 目標の設定・管理方法の１つで、Objective と KeyResults の略称\n勉強のために読んだ本によると、\n第一の原則は、みんなのモチベーションを高めて最高の仕事をしてもらう方法、 第二の原則は、有意義な形で進捗を測る方法と言える\nOKR（オーケーアール） | クリスティーナ・ウォドキー (著)\nとも書いてあり、それぞれ Objective と KeyResutls を表していると思われる\nまた OKR は、スタートアップのような小規模のチームから Google のような大企業まで活用することができる目標設定のフレームワークである。\nOKR の決め方 会社のミッションを確認する 世界を変えたいと思って起業された会社にはミッションがあるはずだ。\nミッションを言語化するにあたり以下のようなものが使える\n私たちは、[価値提案]によって、[市場]における[問題を取り除きます/生活を向上させます]\nOKR（オーケーアール） | クリスティーナ・ウォドキー (著)\n上記の本では会社を 5 年間支えてくれるようなミッションを設定してね、と言われてる\n市場の変化や会社の方針などによって色々在るが 5 年間は頑張ろうという意味でもあるのかな。\nObjective と Key Results の理解 これはとてもシンプルで前述している通り、Objective と KeyResults のみからなる。\n各項目は以下のような性質を持つ\nObjective 定性的でチームのテンションが上がるような１文にまとめる チームが独立して実行できるものにする 達成のための期間を設定する、例えば四半期や半期などを考えられる KeyResults Objective で設定した感覚的なことばを定量化する 達成するのが困難だが、不可能ではないものを設定する Objective と KeyResults の設定 実はこれの決め方についてはあまり紹介されている書籍やブログなどが見当たらなかった。\n一方で実際に OKR をやってみて思うのは、「実行するチームが Objective を深く理解すること」が最も重要なことだと思った。\nいろいろなワークショップ手法や雑談など何でもいいが、チームが OKR をやることを心から納得していて、設定された Objective を自分にとって達成したいと思えるものに言い換えることができればあとはなんでもよい。\nあとで Good/Bad などまとめるが、それよりも上記を達成することに力を注いだほうが絶対にいい結果になる。\nちなみに会社のミッションの設定から OKR の設定まで 4 時間ほどで完了できたら順調くらいの温度感。\nOKR Tree これは必要な組織のみやれば良い\nまずは会社のミッションから経営層などが OKR を設定し、その KeyResults を下位組織の Objective を同等の関係性になる\nイメージはこんな感じ、\nMission 会社の Objective 会社の KeyResults KeyResult 1 (= 部署 1 の Objective) 部署 1 の KeyResult 1 部署 1 の KeyResult 2 KeyResult 2 (= 部署 2 の Objective) 部署 2 の KeyResult 1 部署 2 の KeyResult 2 OKR の Good/Bad とその例 Good \u0026#x1f44d; Objective は若干気後れするくらい高いレベルに設定する KeyResults は評価を単純にするために数値化して測定する OKR を組織全体に公開する 会社に来ることが楽しみになるような目標になっている Bad \u0026#x1f44e; 個人を評価するために使う タスク管理のために利用する OKR の運用 毎週月曜日に１週間の仕事を計画し、金曜日にその達成を祝う。というのが基本のリズム\n月曜日の計画でやること 今週の最優先事項の設定 今後 4 週間 OKR の自信度状況の更新 健康・健全性指標の確認 水~木曜日 ここでは計画したことを実行\n金曜日に Win Session 月曜日に計画したことの達成有無を確認する\n達成のためにやったメンバーの素晴らしい仕事や助けられたことなど些細なことでもお互いに褒める\nあまり書籍などには書かれていないが、逆にそうではないことを指摘する場にもなるといいと思う。 （これが褒めることが目的になって馴れ合いっぽくなって改善されないこともあるので）\nOKR を振り返る OKR ははじめ失敗することが当たり前とされている\n最初に設定した期間が終了した時点でその間どうだったかを振り返る\n設定した Objective は本当に野心的だったか 難易度が低く達成できてしまった 抽象的すぎて日々意識することができなかった etc 運用方法について KeyResults が計測できる形でなく進捗を計測できなかった 毎週 Objective に近づけるタスクを立てられなかった etc 正直この当たりは実行した組織によっていろいろ在ると思う。\nこれをしっかり運用できるか、失敗を前提としてチームが振り返ることができるかが重要だと感じる。\nなぜ OKR は失敗するのか 参考にした書籍には、OKR 導入の最初は失敗するものだと明言されている。\n実際はわからないが、チームが合意できてなかったり、会社のミッションと関係性が作れていなかったりなどあるだろうが、いずれにしてもそれを四半期で振り返り、改善することができなかったら成功することは無いと思う\nまとめ まずは正式なフレームに沿って運用するべき 最初は失敗するのが前提 設定した期間が終了したら OKR を振り返り改善することを必ずする あたりを守っておけばひとまず運用はスタート出来るんじゃ無いかと思った\nあとは Google re:works のブログなど見ると良さそう\n","permalink":"https://konumaru.org/202206/okr%E3%82%84%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%AB%E7%9F%A5%E3%81%A3%E3%81%A6%E3%81%8A%E3%81%8D%E3%81%9F%E3%81%84%E3%81%93%E3%81%A8/","summary":"\u003cp\u003e目標設定のフレームワークとして OKR を採用することにしたので、OKR 導入のために必要な基礎的な知識をまとめる。\u003c/p\u003e\n\u003ch2 id=\"okr-とは\"\u003eOKR とは\u003c/h2\u003e\n\u003cp\u003e目標の設定・管理方法の１つで、Objective と KeyResults の略称\u003c/p\u003e","title":"OKRやるときに知っておきたいこと"}]