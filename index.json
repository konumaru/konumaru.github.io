[{"content":"コンペ概要 hogehoge\n解法 1st  code GBDT + NNのアンサンブル  XGBoost  Treeliteで推論高速化   1dcnn  transformerを試したが、同じスコア+軽量だったため1dcnnを採用     閾値は0.625で固定  閾値は個別に設定するとモデルの堅牢性が低かった   特徴量の数は、各level_groupで 663、1993、3734 indexをソートしたものと、元の順序の両方のモデルを作成 cv=0.705  2nd  単一のLightGBMで予測  level_groupごとにモデルを分けていない   5-fold cvで評価、予測用に全データでモデルを学習 特徴量生成にはnumba, Cを使った  level=1の回答に費やした時間？が効いた   特徴量は1,296個 閾値は0.63で固定  3rd  levelごとにモデルを学習（18個の2値分類モデル） GBDT + NNのアンサンブル  Catboost * 2, xgb * 2 transformer + lstm   ローデータをsession_idごとのindexでソート 特徴量の数は、1,000個、2,000個、2,400個  前のlevel_groupからの経過時間 過去質問の予測確率（自分の場合は効かなかった） permutation importanceで特徴量選択   cv=0.702  4th  Transformer, XGB, Catboostのアンサンブル  3 seed, 5 fold   線形モデルでアンサンブル indexでソート後、hover行を削除し再度indexを作成した level_groupごとにモデルを学習しているが、nnモデルの共通部分の定義がうまい cv=0.704 異なる閾値（0.60, 0.62, 0.64）の最終提出３つを選んだ  結果的には0.61が最もprivate scoreが高かった    7th  level_groupごとにモデルを学習  予測時間短縮のため、levelごとにモデルを分割しなかった 評価時はcv分割したが、推論用には全データで学習したモデルを使用   特徴量  集約キーはlevel、name、event_name、room_fqid、fqid、text 集約キーごとの前のイベントとの時間差、カウント event_name=notification_clickのレコードが重要だった（？） 集約キーの組み合わせが多いため、出現回数が低いものは除外した   モデリング  高い学習率(0.1)で学習し、特徴量重要度(gain)が低いものを除外 低い学習率(0.02)で再度学習   cv=0.7034 閾値は0.625で固定  金圏との差分  特徴量の数が足りなかった Leakを考慮した特徴量重要度を用いた特徴量選択ができなかった  全foldで特徴量重要度を平均して選択するのはダメ  検証用データの特徴量重要度を知ってしまう状態になってしまう   foldごとに特徴量重要度を平均し、評価する必要があった jackさんの解法では、最後にcvを切らず全データを使った学習をしているがそのときはfoldごとの特徴量重要度を平均したものを使っている   閾値を固定していない GBDT + NNのアンサンブルを試していない  ","permalink":"https://konumaru.com/posts/psp%E3%82%B3%E3%83%B3%E3%83%9A%E6%8C%AF%E3%82%8A%E8%BF%94%E3%82%8A/","summary":"コンペ概要 hogehoge 解法 1st code GBDT + NNのアンサンブル XGBoost Treeliteで推論高速化 1dcnn transformerを試したが、同じスコア+軽量だったため1dc","title":"PSPコンペ振り返り"},{"content":"コンペ概要 コンペページはこことは\nドイツ最大級のオンラインショップOTTOを題材に特定のユーザがどの商品に対し、クリック、カート追加、注文するかを予測する。\nデータはアイテム数180万、ユーザ数1200万人、インタラクション数2.2億が与えられる。これらのデータは４週間のインタラクション履歴からなる。 3週間分をtrain, 残り1週間をtestとして扱う。また、train, testでユーザの重複はない。\n評価は、各インタラクション（click, cart, order）ごとにRecall@20の重み付き平均和で計算される。\n解法の概要  Model  Candidate Generation (Recall) Rerank   CV Strategy  5%のユーザを使う    上位解法 1st place solution  Candidate Generation  NNでEmbeddingを作成  session embedding aid embedding   学習時は上記を使って、positive, negativeサンプリングをそれぞれ行いRerankerが学習するデータを選出  cos similiarityが (avg + min) / 2 以上のものをpositiveとする？     Reranker  LGBMRanker  Feature  session * aidを使ったcandi        まとめ ","permalink":"https://konumaru.com/posts/kaggle-otto%E3%82%B3%E3%83%B3%E3%83%9A%E8%A7%A3%E6%B3%95%E8%AA%BF%E6%9F%BB/","summary":"コンペ概要 コンペページはこことは ドイツ最大級のオンラインショップOTTOを題材に特定のユーザがどの商品に対し、クリック、カート追加、注文する","title":"kaggle OTTOコンペ解法調査"},{"content":"何を作ろうと思ったのか ひとことで言うと「マッチングアプリに変わる恋愛シュミレーションAI」を作りたかった。\nChatGPTを使ってみたところかなり自然に会話をしてくれたので、まるで人と話しているかに感じることができた。 それを受けてプロンプトで人格を定義して、シュミレーションゲーム風にして人と話すことを目的にしているマッチングアプリユーザをリアルの人と関わることによるストレスから解放できないかと思いつくってみることにした。\nついでにStripeを使って有料化しようと思ったが、そこまでの品質にはならなかった。\n出来上がったもの 詳細はGithubを参照してください。\n正直人と話ている状態とはほど遠く、実験的に作った４択形式のインターフェースが楽ではあったがリアルから離れすぎてしまった。\nアーキテクチャはこんな感じ\nプロンプトエンジニアリングの難しさ GPT3.5だったのもあったが、出力を安定させるのが非常に難しかった。\njsonで出力されることが担保されるならMessaging APIで提供されているクイックリプライを使いたかった\nまた、口調を人っぽくするだけなら簡単だったがなんとも言えない会話の成立のしなさが解決できなかった。 必ず返答をしてくれるのだが、会話が堂々巡りしてしまったらだらだらとやり取りが続いてしまう。\nあとは動作テストをChatGPTでやっていたが、実際にはLangchianを使って実装している。 今回はやらなかったが、Langchianをつかうならいくつかの役割にBotを分離させて並列に複数の処理をさせることで\n 記憶の単純化 レスポンス速度の向上 プロンプトの簡略化  などを期待できたかもしれないと思った。\nLINEというインターフェースの良さ 簡単にいくつか上げると\n 簡単にリッチなUIが使える 使い慣れているインターフェースなので受け入れられやすい  友達と飲んでいる時にちょっとこれつかってみてよ。がやりやすかった   GPTのデメリットであるレスポンスの遅さがLINEだと意外と自然  とはいえ、連投とかされると困った    LINEのデメリット 唯一デメリットは、動作テストのしにくさだった。\n ngrokでローカルにエンドポイントを立てる LINE Messaging APIにエンドポイントを再登録 function frameworkでCloud Functionのローカルサーバを立てる 手元のデバイスでLINE使って動作テスト  などやっている間にデプロイしてしまったほうが楽だったりした。\n完成までの反省点 遅い。シンプルに納得がいくところまで作り終えるのが遅かった。 動かすだけなら一晩で作ることができきたが、プロンプトエンジニアリングが難しかった。\nインフラ面では、始めにタイムアウトを気にしてCloud Runを使っていたが、結果的にはCloud Functionで動かすことにしてことで開発が二度手間になった。\n開発過程で取り組んで良かったこと 以下の企画書を書いたのはよかった。 目的決めて、期日、撤退ラインなどを事前に決めておくのは本当によかった。\n# 企画書 ## サービス内容 ## 証明したいこと ## 実現可能性 ## リリース目標 ## インフラ ## 実装方針 ## お金回り ## 撤退ライン ## 広める方法 ","permalink":"https://konumaru.com/posts/gpt-3.5%E3%81%A7%E4%BD%9C%E3%81%A3%E3%81%9F%E6%81%8B%E6%84%9B%E3%82%B7%E3%83%A5%E3%83%9F%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3ai-chatbot/","summary":"何を作ろうと思ったのか ひとことで言うと「マッチングアプリに変わる恋愛シュミレーションAI」を作りたかった。 ChatGPTを使ってみたところか","title":"GPT-3.5で作った恋愛シュミレーションAI ChatBot"},{"content":"概要 教師なし学習を使った異常検知をやってみたいと思い 、Pythonではじめる教師なし学習を読んでいたらちょうど いいお題があったのでやってみることにした\nここではサンプルデータを対象にPCAを使った異常検知を行う\nなぜ検出できるのかという理論的な内容についてはここでは触れない。（というかわかっ てない）\nアプローチ PCAについて はこのPDFが 詳しく書いてあった\n前提として、なんらかの理由で訓練データに異常標本が混ざっており、教示データを用意 できないこととする。\n（専門家の方には怒られてしまう表現なのは重々承知で、）\n上記の資料ではPCAは以下のように説明されている\n 多次元データのもつ情報をできるだけ損わずに低次元空間に情報を縮約する方法\n この性質を使って、\n 異常標本が混ざっている多次元データ 1のデータをPCAで次元圧縮し、固有値ベクトルを取得 1と2のデータを使って一度次元圧縮し、復元した逆変換データを作る 元データと逆変換データの差分が大きい値を異常標本として検出する  上記のような処理をすることで、一度PCAをした際に正常なデータの方が多いことが想定されるため、Fitされるベクトルが正常標本に偏りと思われる\nその性質を利用して、逆変換をした際に異常標本は正常データに偏って変換されるため元データとの差分が正常標本よりも大きくなると考えられる\nPCA を使った異常検知の実装 実装したscriptはこちら\n２値分類のサンプルデータを生成 from pyod.utils.data import generate_data X_train, _, y_train, _ = generate_data( n_train=2000, n_test=0, contamination=0.1, # percentage of outliers random_state=42, ) X_trainとy_trainの中身\nX_train: (2000, 2) [[6.43365854 5.5091683 ] [5.04469788 7.70806466] [5.92453568 5.25921966] [5.29399075 5.67126197] [5.61509076 6.1309285 ]] y_train: (2000,) [0. 0. 0. 0. 0.] 以下は入力データの分布の画像だが、特徴量を見ても別のデータとして視認できそう PCA を使ってデータを逆変換 import numpy as np from sklearn.decomposition import PCA def fit_and_inverse(data: np.ndarray, n_components: int = 2): pca = PCA(n_components=n_components) reduced = pca.fit_transform(data) inverse = pca.inverse_transform(reduced) return inverse raw = X_train.copy() inv = fit_and_inverse(raw) 元データと逆変換データの差分から閾値を決定 mse = ((raw - inv) ** 2).mean(axis=1) # NOTE: # 今回は10%が異常データとして生成してるので90percentileで閾値を設ける # 実際には想定される異常値の割合や期待する再現率などから設定すると考えられる threshold = np.percentile(mse, 90) 以下の画像が標本ごとのMSEの分布と閾値になる\n分布からはこれが良い閾値なのかはわかりにくいと思った\n分類結果     precision recall f1-score support     1.0 0.91 0.70 0.79 200   0.0 0.97 0.99 0.98 1800    まとめ PCAを使った異常検知の手法ということで、ラベルデータがない環境下でも取れる手段としていい知見になった。\n使っている手法がPCAになるのでカテゴリカルデータや元データの次元数が多い時などさまざまな場面では制約になることがあるのかなあとか思った。\n","permalink":"https://konumaru.com/posts/pca%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E7%95%B0%E5%B8%B8%E6%A4%9C%E7%9F%A5/","summary":"概要 教師なし学習を使った異常検知をやってみたいと思い 、Pythonではじめる教師なし学習を読んでいたらちょうど いいお題があったのでやってみる","title":"PCAを使った異常検知"},{"content":"コンペ概要 ざっくりの概要はサッカーの試合動画(45min * 2) から特定のフレームで Challenge, Play, Throwin の３つのイベントを予測するというもの\n（合っているか不安だが、）サッカー業界の事情としては、ユース、プロ、セミプロなど は手厚い指導を受けられるが、それ以外のプレイヤーは質の良い指導を受けられるほど人 材は充実していない。\nこれを画像処理の技術によって試合中の選手の活動状況を把握することで少ない人的コス トで選手に有益なアドバイスをできないか、という取り組み。\n評価指標 公式の説明 はここ\nsubmission file は以下 Columns を必要とした csv ファイルを提出する。\n video_id: 動画の識別子 time: event が発生した動画内の時間 event: challenge, play, throwin の内、発生したイベントを１つ score: イベントが発生した確率（後に Average Precision を算出するときに使う）  このコンペの評価を簡単に説明すると以下のような計算を行います\n 各 event について Average Precision を計算 その際に下記の Tolerances (許容度)に従い、正解ラベルとの time の誤差以内であれ ば正解とする  つまり１つのラベルで time の誤差０であれば５回予測できたとする   最後に３つの event の Average Precision の平均値を評価指標とする  # Tolerances Challenge: [ 0.30, 0.40, 0.50, 0.60, 0.70 ] Play: [ 0.15, 0.20, 0.25, 0.30, 0.35 ] Throw-In: [ 0.15, 0.20, 0.25, 0.30, 0.35 ] 本コンペで難しいと感じた部分  データが動画  動画によってカメラの画角が捉えてる範囲が異なる 客席も映像に入ってる   コードコンペだったので CPU/GPU 共に 9 時間の制限がある Discussion の情報が乏しい（画像処理の経験が浅いのでつらかった）  （ここの言語化ができてない時点で負けている感がある\u0026hellip;.）\n自分が取り組んだ内容 当時のRepository\n(Private にしていると思うので見れません。)\n Yolov7 で ball, person の x,y,conf を取得 時系列テーブルデータとして特徴量エンジニアリング  ball の xy 座標と confidence 予測対象フレームの-20~20 のフレーム前後の ball の xy 座標と confidence 予測対象フレームの-20~20 のフレームで rolling した ball の xy 座標と confidence の統計量 予測対象フレームの-20~20 のフレーム間で ball が移動したベクトルの内積と角度 検出された person 全員の座標の統計量   XGBoost で学習、損失関数は LogLoss Group=game_id(video_id から前半後半を統合), k=3 の GroupKFold で評価  結果は、ローカルで 0.2 と戦えるスコア出なかった\nplay だけは 0.7 近く予測できたが、challenge と throwin は 0.02 程度だった\n上位解法 1st Solution  4 つの動画を固定で検証用に使った 1024*1024 のグレースケールで前後のフレームを使った 3 チャンネルの画像を使用  処理速度を考慮   efficientnetv2_b0, efficientnetv2_b1 を使用  3dcnn は pooling 前の最終ブロックと最後の畳み込み層のみ 小さいデータセットに対して過学習することはすぐに分かった   損失関数は３つのカラムで BCE  ダミーデータはどうしてたんだろう？   マルチスレッド化して推論を高速化  １つの video で 25 min であり、モデルを 2 つしようしたので 50 min 最終的には全体で 5 hours    2nd Solution  オプティカルフロー  オプティカルフローを予測？ RAFT というアイデアを使ってる   ボールの検出  対象フレームの RGB、前後のオプティカルフローのブレームの RGB の合計 9channel を使用  検出された Ball のヒートマップの内、上位 10 に厳選     ボール軌道のコスト最小化  N フレームを対象にボール検出で厳選された 10 の ball から軌道を考慮すると尤も らしいものを選定   イベント分類  ボール周辺の画像をトリミングしたものを使用 2D CNN + Ball 軌道特徴量 -\u0026gt; 1D CNN -\u0026gt; 4 Event Class Prediction（短期予測？） Stacking 51 フレームの簡易的な特徴量から中間の７フレームを対象に予測（長期予測？）   後処理  Play\u0026amp;Pass については７フレームの内？予測値が peek の time を採用 Challenge についてはノイズが多かったので予測値にガウシフィルターを適用後同様 の処理でイベント発生 time を選定    3rd Solution  EfficientNet + Simple 1D UNet  input=(1, 64, 3, 360, 640) 前後に 64 フレームも使ってる！？ 64 フレーム中で score が peek のフレームを採用 Backbone をフリーズさせることで学習を高速化   ボール検出の pretraining  そのまま学習するとオーバーフィットする ボールの位置を教えることで解決 ボールの位置は自分でアノテーションした（自分でアノテーションは頭になかった \u0026hellip;）   ラベルデータの加工  正解ラベルを中心に緩やかに正解にする(0~1 のグラデーションを持たせる)  正解ラベルの周辺フレームは event に近い動きをしているはずなのでそのニュア ンスを表現することでモデルの FalesNegative を抑制してる？     Augmentation  RandomHorizontalFlip, RandomRotation, ColorJitter, etc   Loss Function は、Focal Loss  Challenge と Throwin はデータが少ないので weight を設定することで調整   推論  imutilsで video のデコードを MultiTread 化  これをつかって動画読み込みむだけで早くなるってことなのか？     後処理  NSM の閾値に[12, 6, 6] for [challenge, play, throwin]と言ってるがどういう ことなのだろう    5th Solution  グレースケール、size=(1024,576), crop_center(960,512) 前フレームとの差 前後 5 フレームの effecientnet_b1 による 3 クラス分類 5 モデルのアンサンブル(CV したモデル) ラベルデザイン  σ=20 フレームのガウス分布  前後 20 フレームについてガウス分布にしたがって緩やかにラベルを付与したって ことだろうか      上位を取るために  そもそも NN を使うということ  Efficientnet, UNet について要復習 入力の３次元は RGB の color channel だけでなく、時間軸にも使える   検証データを固定した試行錯誤の時間の削減  最初は画像サイズを小さくなども   ガウス分布を使ったラベルの重みづけ 動画読み込みの並列化による推論の高速化 既存のライブラリやモジュールを活用したスタートラインを高く持つ志  諸刃の剣かもしれんが、少なくとも画像コンペにおいては\u0026hellip;？    お気持ち 「知っていて出来なかったこと」と「知らなくて出来なかったこと」があったように感じ た\n知っていてできなかったことは、今回の問題と紐づかなかったのでどうすればよいのか難 しいが、少なくとも知らなかったことは知っているに変えたい\n","permalink":"https://konumaru.com/posts/kaggle%E3%82%B3%E3%83%B3%E3%83%9A-dfl%E5%8F%8D%E7%9C%81%E4%BC%9A/","summary":"コンペ概要 ざっくりの概要はサッカーの試合動画(45min * 2) から特定のフレームで Challenge, Play, Throwin の３つのイベントを予測するというもの （合っているか不安","title":"kaggleコンペ DFL反省会"},{"content":"これを読んで得られるもの PM, Desingner, Developerの間で、何を、何故作るのかの共通認識を作るための手段\nPRD とは  「プロダクトマネージャー本人も含めて、常に立ち返るべき方針」をドキュメントにしたもの ブレの無い意思決定をするため 開発終盤に入り期日も近づいた時の取捨選択を判断する基準  より詳しい内容については及川さんというかたが公開されているはじめてのPRDがとても参考になる\nPRD のテンプレート 以下はProduct Huntのものを参照している。\n合わせてnoteに投稿されていた記事も非常に参考になった。\n# Title ## Intro \u0026amp; Goal ## Product Vision ## Who\u0026#39;s it for? ｜誰のためにあるか ## Why build it?｜なぜ創るか ## What is it?｜どういうものか ### Glossary ｜用語 ### User Types ### UI/Screens/Functionalities ｜ UI/画面/機能 ## Brainstormed Ideas ｜その他アイデア ## Competitors \u0026amp; Product Inspiration ｜競合 ## Seeding Users \u0026amp; Content ｜初期ユーザーと獲得戦略 ## Mockups ## Tech Notes PRD を書くステップ PRDの作成ステップについては以下の記事がとても参考になった。\nProduct Templates: Product Requirements Document (PRD)\n 素案を書く  Good Ideaをプライベートドキュメントに書いてみる 言語化の過程で自らが間違っていたことに気づくかもしれません Backgroud, Objective, metricsは最低限欲しい  さらに、ユーザーが利用するシナリオ、主要機能を言語化できると素晴らしい     上長の承認を得る  上司の考えやフィードバックを入手するのが目的  自分よりもドメイン知識を豊富に持っている人の意見は貴重です   また情報の透明性にも繋がります   デザイナーと共有  エンジニアリングについて語る前にユーザーに触れさせるのが懸命です デザイナーの意見を積極的に仕様に反映させましょう   エンジニアと共有  （理想的には）デザイナーとエンジニアのリーダーと PRD を共有し、フィードバックを得ます 技術的に実現可能なものを見つけ、大まかな時間・難易度の見積りを行う   プロダクトチーム全体に共有  この時点で正式に会社のwikiにPRDを移動 チームから得た質問や情報をPRDに記録していきます  プロダクトチームから良きアイデアが出た場合、初期に実現しないとしてもここにメモします     会社に共有  必要に応じて、プレゼンテーションの材料とすることができます    ","permalink":"https://konumaru.com/posts/prd-what%E3%82%92%E6%B1%BA%E3%82%81%E3%82%8B%E3%81%9F%E3%82%81%E3%81%AE%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88/","summary":"これを読んで得られるもの PM, Desingner, Developerの間で、何を、何故作るのかの共通認識を作るための手段 PRD とは 「プロダクトマネージャー本人も含めて","title":"PRD - Whatを決めるためのドキュメント"},{"content":"経緯  諸事情により、PC を新しくしたところ hugo server がローカルで起動しなくなった よく確認せずに Github Actions へビルドしたら CI は通過したのでローカル環境の問題だと推測した  エラーメッセージ hogehoge\n❯ hugo server -D Start building sites … hugo v0.102.3+extended darwin/amd64 BuildDate=unknown WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for layout \u0026#34;archives\u0026#34; for kind \u0026#34;page\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;term\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;term\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;page\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;term\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;term\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;page\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;term\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;home\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for layout \u0026#34;search\u0026#34; for kind \u0026#34;page\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination. WARN 2022/09/13 10:56:07 found no layout file for \u0026#34;HTML\u0026#34; for kind \u0026#34;taxonomy\u0026#34;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination 対応 原因は、サブモジュールを初期化\u0026amp;更新する必要があった\n\u0026gt; git submodule update --init --recursive 更新するだけでなく、初期化が必要な部分でつまづいた。\n","permalink":"https://konumaru.com/posts/202209%E6%99%82%E7%82%B9%E3%81%A7%E8%B5%B7%E3%81%8D%E3%81%9Fhugo%E3%83%93%E3%83%AB%E3%83%89%E3%82%A8%E3%83%A9%E3%83%BC%E5%AF%BE%E5%BF%9C/","summary":"経緯 諸事情により、PC を新しくしたところ hugo server がローカルで起動しなくなった よく確認せずに Github Actions へビルドしたら CI は通過したのでローカル環境の問題だ","title":"202209時点で起きたHugoビルドエラー対応"},{"content":"「クリストファー・アレクサンダーの思考の軌跡 - デザイン行為の意味を問う」を読んだ感想をまとめる\n形は機能に従う、機能は形に従うのではない 「形は機能に従う」\nこれがこの本の中で最も重要だった言葉だと感じました。\n様々なニーズを満たすものの形は、そのニーズを満たすような機能が先だって定められ、その機能を満たす形がおのずと決まる。ということを言っている。\nデザイナーと自然科学者の対比 本書では扇風機の説明の仕方を例にその違いを対比していた。\nデザイナー観点での扇風機の説明\n 扇風機はその前にいる人を涼しくするという機能を持っている\n クリストファー・アレクサンダーの思考の軌跡 - デザイン行為の意味を問う | 長坂 一郎 (著)\n  自然科学者観点での扇風機の説明\n 扇風機は羽を回転させて（最近は翅のないものもあるが）、一定の風速の空気の流れを発生させるという機能を持っている\n クリストファー・アレクサンダーの思考の軌跡 - デザイン行為の意味を問う | 長坂 一郎 (著)\n  この２つの「機能」の説明は全く異なり、デザイナーの観点からは扇風機が作られた目的が説明されている。\n自然科学者の観点からでは「機能は形に従う」説明になっている。機能に先だって形が存在していることになる。\n例えば、「キリンの高いところにある葉を食べる（機能）から首が長い（形）のだ」のようになる。 （キリンは高いところにしか葉がないから首が長くなったのではなかっただろうか。）\nこの「機能」の捉え方がデザインにとって最も根底にあることだと思われる。\nデザイナーにとっては、形に先だって機能があるという考え方によって再現あるよいデザインをすることができるのではないかとこの本では言われている。\nデザイナーの仕事 デザイナーの仕事は、この「機能」が目的としている「ニーズ」を定義し、分析することにある。（と読み取れた。)\nここでの「ニーズ」は～を求めている。ではなく、～をしようとしている。などの傾向のことを言う。\n本書では「ニーズ」＝「人々がしようとすること」と概念を置き換えている。\nデザイナーはこの「人々がしようとすること」が何らかの理由で実行できないとき、それを様々なモノの粒度や関係性を変えることで、ユーザが実行できる状況を作り出すことが仕事になる。\nこの目指す状況の違いに特定の人、デザイナーならではの個性が現れるのだと思われる。\nオーダーメイドっていいもんなんだな、 この本を読んでオーダーメイドというは、このプロセスをひとり占めできるのだからそれは贅沢なものなのだと気づいた。\n他の誰のためのものでもなく、自分だけのためにニーズを分析して、形を作る。\nこのプロセスを経て作られたものがいいものでない訳がない。\n","permalink":"https://konumaru.com/posts/%E5%BD%A2%E3%81%AF%E6%A9%9F%E8%83%BD%E3%81%AB%E5%BE%93%E3%81%86/","summary":"「クリストファー・アレクサンダーの思考の軌跡 - デザイン行為の意味を問う」を読んだ感想をまとめる 形は機能に従う、機能は形に従うのではない 「形は","title":"形は機能に従う"},{"content":"目標設定のフレームワークとして OKR を採用することにしたので、OKR 導入のために必要な基礎的な知識をまとめる。\nOKR とは 目標の設定・管理方法の１つで、Objective と KeyResults の略称\n勉強のために読んだ本によると、\n 第一の原則は、みんなのモチベーションを高めて最高の仕事をしてもらう方法、 第二の原則は、有意義な形で進捗を測る方法と言える\n OKR（オーケーアール） | クリスティーナ・ウォドキー (著)\n  とも書いてあり、それぞれ Objective と KeyResutls を表していると思われる\nまた OKR は、スタートアップのような小規模のチームから Google のような大企業まで活用することができる目標設定のフレームワークである。\nOKR の決め方 会社のミッションを確認する 世界を変えたいと思って起業された会社にはミッションがあるはずだ。\nミッションを言語化するにあたり以下のようなものが使える\n 私たちは、[価値提案]によって、[市場]における[問題を取り除きます/生活を向上させます]\n OKR（オーケーアール） | クリスティーナ・ウォドキー (著)\n  上記の本では会社を 5 年間支えてくれるようなミッションを設定してね、と言われてる\n市場の変化や会社の方針などによって色々在るが 5 年間は頑張ろうという意味でもあるのかな。\nObjective と Key Results の理解 これはとてもシンプルで前述している通り、Objective と KeyResults のみからなる。\n各項目は以下のような性質を持つ\n Objective  定性的でチームのテンションが上がるような１文にまとめる チームが独立して実行できるものにする 達成のための期間を設定する、例えば四半期や半期などを考えられる   KeyResults  Objective で設定した感覚的なことばを定量化する 達成するのが困難だが、不可能ではないものを設定する    Objective と KeyResults の設定 実はこれの決め方についてはあまり紹介されている書籍やブログなどが見当たらなかった。\n一方で実際に OKR をやってみて思うのは、「実行するチームが Objective を深く理解すること」が最も重要なことだと思った。\nいろいろなワークショップ手法や雑談など何でもいいが、チームが OKR をやることを心から納得していて、設定された Objective を自分にとって達成したいと思えるものに言い換えることができればあとはなんでもよい。\nあとで Good/Bad などまとめるが、それよりも上記を達成することに力を注いだほうが絶対にいい結果になる。\nちなみに会社のミッションの設定から OKR の設定まで 4 時間ほどで完了できたら順調くらいの温度感。\nOKR Tree これは必要な組織のみやれば良い\nまずは会社のミッションから経営層などが OKR を設定し、その KeyResults を下位組織の Objective を同等の関係性になる\nイメージはこんな感じ、\n Mission  会社の Objective 会社の KeyResults  KeyResult 1 (= 部署 1 の Objective)  部署 1 の KeyResult 1 部署 1 の KeyResult 2   KeyResult 2 (= 部署 2 の Objective)  部署 2 の KeyResult 1 部署 2 の KeyResult 2        OKR の Good/Bad とその例  Good 👍  Objective は若干気後れするくらい高いレベルに設定する KeyResults は評価を単純にするために数値化して測定する OKR を組織全体に公開する 会社に来ることが楽しみになるような目標になっている   Bad 👎  個人を評価するために使う タスク管理のために利用する    OKR の運用 毎週月曜日に１週間の仕事を計画し、金曜日にその達成を祝う。というのが基本のリズム\n月曜日の計画でやること  今週の最優先事項の設定 今後 4 週間 OKR の自信度状況の更新 健康・健全性指標の確認  水~木曜日 ここでは計画したことを実行\n金曜日に Win Session 月曜日に計画したことの達成有無を確認する\n達成のためにやったメンバーの素晴らしい仕事や助けられたことなど些細なことでもお互いに褒める\nあまり書籍などには書かれていないが、逆にそうではないことを指摘する場にもなるといいと思う。 （これが褒めることが目的になって馴れ合いっぽくなって改善されないこともあるので）\nOKR を振り返る OKR ははじめ失敗することが当たり前とされている\n最初に設定した期間が終了した時点でその間どうだったかを振り返る\n 設定した Objective は本当に野心的だったか  難易度が低く達成できてしまった 抽象的すぎて日々意識することができなかった etc   運用方法について  KeyResults が計測できる形でなく進捗を計測できなかった 毎週 Objective に近づけるタスクを立てられなかった etc    正直この当たりは実行した組織によっていろいろ在ると思う。\nこれをしっかり運用できるか、失敗を前提としてチームが振り返ることができるかが重要だと感じる。\nなぜ OKR は失敗するのか 参考にした書籍には、OKR 導入の最初は失敗するものだと明言されている。\n実際はわからないが、チームが合意できてなかったり、会社のミッションと関係性が作れていなかったりなどあるだろうが、いずれにしてもそれを四半期で振り返り、改善することができなかったら成功することは無いと思う\nまとめ  まずは正式なフレームに沿って運用するべき 最初は失敗するのが前提 設定した期間が終了したら OKR を振り返り改善することを必ずする  あたりを守っておけばひとまず運用はスタート出来るんじゃ無いかと思った\nあとは Google re:works のブログなど見ると良さそう\n","permalink":"https://konumaru.com/posts/okr%E3%82%84%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%AB%E7%9F%A5%E3%81%A3%E3%81%A6%E3%81%8A%E3%81%8D%E3%81%9F%E3%81%84%E3%81%93%E3%81%A8/","summary":"目標設定のフレームワークとして OKR を採用することにしたので、OKR 導入のために必要な基礎的な知識をまとめる。 OKR とは 目標の設定・管理方法の１つで","title":"OKRやるときに知っておきたいこと"}]